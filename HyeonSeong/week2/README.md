# LLM을 활용한 실전 AI 애플리케이션 개발
------------------
# 12 벡터 데이터베이스로 확장하기: RAG 구현하기
## 12.1 벡터 데이터베이스란
**벡터 데이터베이스** - 벡터 임베딩(데이터의 의미를 담은 숫자 배열)을 키로 사용하는 데이터베이스   

### 12.1.1 딥러닝과 벡터 데이터베이스
**표현 학습** - 기존의 머신러닝에서는 매번 새롭게 특징을 정의하는 단계가 필요했지만 딥러닝에서는 데이터만 충분하다면 모델이 알아서 이런 특징을 뽑는 과정도 학습   

그림 12.4   

비슷한 데이터는 가깝게 있고, 다른 데이터는 멀리 위치하게 되는 임베딩 벡터의 특징을 이용해 서로 비슷한 데이터를 찾을 수 있음   
벡터 데이터 베이스를 활용하기 위한 3단계   
1. 저장: 저장할 데이터를 임베딩 모델을 거쳐 벡터로 변환하고 벡터 데이터베이스에 저장
2. 검색: 검색할 데이터를 임베딩 모델을 거쳐 벡터로 변환하고 벡터 데이터베이스에서 검색
3. 결과 반환: 벡터 데이터베이스에서는 검색 쿼리의 임베딩과 거리가 가까운 벡터를 찾아 반환

벡터 사이의 거리를 측정하는 다양한 방법이 있는데 일반적으로 유클리드 거리, 코사인 유사도, 점곱(dot product)을 가장 많이 활용   
### 12.1.2 벡터 데이터베이스 지형 파악하기
벡터 임베딩을 저장하고 검색하는 기능을 구현할 때 크게 아래와 같은 소프트웨어를 접함   
1. **벡터 라이브러리** - 메타의 Faiss, 스포티파이의 Annoy 와 같이 벡터를 저장하고 검색하는 핵심 기능을 구현   
2. **벡터 전용 데이터베이스** - 파인콘(Pinecone), 위비에이트(Weaviate)
3. **벡터 기능 추가 데이터베이스** - 일래스틱서치(Elasticsearch), PostgreSQL과 같이 기존의 데이터베이스에 벡터 저장과 검색 기능을 추가   
벡터 데이터베이스는 벡터 라이브러리와 다르게 아래와 같은 기능을 제공   
1. 메타 데이터의 저장 및 필터링 가능
2. 데이터의 백업 및 관리
3. 모니터링, 관련 AI 도구 등 에코시스템과의 통합
4. 데이터 보안과 엑세스 관리   

그림 12.7

고급 벡터 검색이 필요하고 워크로드가 큰 경우 그림 왼쪽의 벡터 전용 데이터베이스를 선택하는 것이 좋음   
벡터 데이터베이스에 대한 이해도가 있고 직접 오픈소스 서비스를 활용해 시스템을 구축할 수 있고 선호한다면 그림 왼쪽 위의 오픈소스 벡터 데이터베이스가 좋음   

## 12.2 벡터 데이터베이스 작동 원리
### 12.2.1 KNN 검색과 그 한계
**KNN(K-Nearest Neighbor)검색** - 검색하려는 벡터와 가장 가까운 K개 이웃 벡터를 찾는 검색 방식   
모든 데이터를 조사하기 때문에 정확하지만 모든 벡터를 조사하기 때문에 연산량이 데이터 수에 비례하게 늘어남   
벡터 검색을 위해서는 먼저 **인덱스**(관계형 데이터베이스의 테이블과 비슷한 레벨)를 만들어야 함   
인덱스를 벡터에 저장하는데, 이렇게 벡터를 저장하는 과정을 "**색인한다**"라고 함   
색인 단계에서는 인덱스의 메모리 사용량과 색인 시간이 중요하고 검색 단계에서는 검색 시간과 재현율이 중요   
**재현율** - 실제로 가장 가까운 K개의 정답 데이터 중 몇 개가 검색 결과로 반환됐는지 그 비율을 나타낸 값   
KKN 검색의 경우 재현율이 100%   

그림 12.8   

### 12.2.2 ANN 검색이란
**근사 최근접 이웃(Approximate Nearest Neighbor)검색** - 대용량 데이터셋에서 주어진 쿼리 항목과 가장 유사한 항목을 효율적으로 찾는 데 사용되는 기술   
대표적인 ANN 알고리즘   
1. **IVF(Inverted File Index)** - 검색 공간을 제한하기 위해 데이터셋 벡터들을 클러스터로 그룹화
2. **HNSW(Hierarchical Navigable Small World)** - 효율적인 ANN 검색을 위한 그래프 기반 인덱싱 구조   
HNSW가 가장 많이 활용되는 ANN 검색 알고리즘   
```
ANN 검색의 재현율 = (KNN으로 찾은 실제 가장 가까운 K개 중 ANN이 찾은 개수) / K
```

### 12.2.3 탐색 가능한 작은 세계(NSW)
HNSW의 그래프는 노드(node)와 간선(edge)로 이루어짐   
1. 노드 - 저장하는 데이터를 의미하고 벡터 데이터베이스에서는 벡터 임베딩이 노드
2. 간선 - 노드와 노드를 연결하는 선으로, 간선을 통해 서로 연결된 노드끼리만 탐색이 가능   

그림 12.9   

탐색 가능한 작은 세계 - 완전히 랜덤한 그래프와 완전히 규칙적인 그래프 사이에 '적당히 랜덤하게' 연결된 그래프 상태   
규칙적인 연결을 통해 정확한 탐색이 가능하면서도 랜덤한 성질을 통해 빠른 탐색이 가능   

그림 12.10   

하지만 랜덤으로 저장하다 보니 아래 그림과 같이 진입점에서 출발했을 때 찾으려는 검색 벡터(Q)와 가장 가까운 점(E)이 아닌 점 A에서 탐색을 멈추는 **지역 최솟값(local mininum)** 문제 발생   

그림 12.13   

### 12.2.4 계층 구조
연결 리스트(linked list) - 새로운 데이터를 추가하거나 삭제할 때 서로를 연결하는 주소 정보를 추가하거나 삭제하면 되기 때문에 데이터 추가/삭제가 자유롭지만 탐색을 할 때는 앞에서부터 순차적으로 확인해야 하기 때문에 탐색 속도가 느림   

그림 12.14   

아래 그림과 같이 데이터가 크기 순으로 정렬되어 있다면 레벨을 나누어 데이터를 듬성듬성 배치하고 탐색은 가장 위층부터 시작   

그림 12.15   

HNSW는 이런 계층 구조를 NSW에 접목해 벡터를 저장하는데 아래와 같은 기준으로 벡터를 저장   
1. 최대가 6인 주사위를 굴려서 6이 나오면 0,1,2층 모두 배치   
2. 주사위를 굴려서 4~5가 나오면 0,1층에 배치
3. 주사위를 굴려서 1,2,3이 나오면 0층에만 배치   

그림 12.16   

## 12.3 실습: HNSW 인덱스의 핵심 파라미터 이해하기
### 12.3.1 파라미터 m 이해하기
HNSW에서 파라미터 m은 추가하는 임베딩 벡터에 연결하는 간선의 수   
벡터에 연결되는 간선이 많을수록 그래프가 더 촘촘하게 연결되기 때문에 검색의 품질이 좋음   

예제 12.4   

표 12.2   

### 12.3.2 파라미터 ef_construction 이해하기
ef_construction은 M개의 가장 가까운 벡터를 선택할 후보군의 크기로, 이 값이 크면 더 많은 후보를 탐색하기 때문에 실제로 추가한 벡터와 가장 가까운 벡터를 선택할 가능성이 높음   

예제 12.5   

표 12.3   

### 12.3.3 파라미터 ef_search 이해하기
ef_search는 ef_construction이 색인 단계에서 후보군의 크기를 결정한 것과 동일하게 검색 단계에서 후보군의 크기를 결정   

예제 12.6   

표 12.4   

## 12.4 실습: 파인콘으로 벡터 검색 구현하기
### 12.4.1 파인콘 클라이언트 사용법
예제 12.8   
파인콘 인덱스에 저장할 수 있도록 tolist() 메서드를 사용해 형태를 변경   
예제 12.9   
예제 12.11   

### 12.4.2 라마인덱스에서 벡터 데이터베이스 변경하기
예제 12.13   

## 12.5 실습: 파인콘을 활용해 멀티 모달 검색 구현하기
### 12.5.1 데이터셋
예제 12.14   

### 12.5.2 실습 흐름
1. 원본 이미지와 세 가지 프롬프트로 생성한 3개의 합성 이미지를 비교   
2. 원본 이미지에 대응되는 '원본 프롬프트'를 입력   
3. 전체 프롬프트 텍스트를 텍스트 임베딩 모델로 저장한 벡터 데이터베이스에 원본 이미지를 이미지 임베딩 모델로 변환한 이미지 임베딩으로 검색해 찾은 '유사 프롬프트'를 사용해 이미지를 생성   

그림 12.19   

### 12.5.3 GPT-4o로 이미지 설명 생성하기
예제 12.15   

### 12.5.4 프롬프트 저장
아래 예제를 통해 프롬프트 임베딩을 저장하고 이미지 임베딩으로 검색할 인덱스를 생성   
예제 12.18   
아래 예제를 사용해 생성한 임베딩 벡터를 벡터 데이터베이스에 저장   
예제 12.20   

### 12.5.5 이미지 임베딩 검색
예제 12.21   

### 12.5.6 DALL-E 3로 이미지 생성
아래의 코드를 사용해 3개의 프롬프트에 대한 이미지를 생성
1. GPT-4o가 원본 이미지를 설명해서 작성한 GPT 설명 프롬프트로 이미지 생성
2. 원본 프롬프트를 사용해 이미지 생성
3. 이미지 임베딩으로 검색한 유사 프롬프트를 사용해 이미지 생성   

예제 12.24

출력결과는 아래와 같이 이미지 생성 파라미터에 따라 생성 결과가 달라지고 랜덤성이 있음   

그림 12.20   

#