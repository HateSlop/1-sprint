# LLM을 활용한 실전 AI 애플리케이션 개발
------------------
# 12 벡터 데이터베이스로 확장하기: RAG 구현하기
## 12.1 벡터 데이터베이스란
**벡터 데이터베이스** - 벡터 임베딩(데이터의 의미를 담은 숫자 배열)을 키로 사용하는 데이터베이스   

### 12.1.1 딥러닝과 벡터 데이터베이스
**표현 학습** - 기존의 머신러닝에서는 매번 새롭게 특징을 정의하는 단계가 필요했지만 딥러닝에서는 데이터만 충분하다면 모델이 알아서 이런 특징을 뽑는 과정도 학습   

그림 12.4   

비슷한 데이터는 가깝게 있고, 다른 데이터는 멀리 위치하게 되는 임베딩 벡터의 특징을 이용해 서로 비슷한 데이터를 찾을 수 있음   
벡터 데이터 베이스를 활용하기 위한 3단계   
1. 저장: 저장할 데이터를 임베딩 모델을 거쳐 벡터로 변환하고 벡터 데이터베이스에 저장
2. 검색: 검색할 데이터를 임베딩 모델을 거쳐 벡터로 변환하고 벡터 데이터베이스에서 검색
3. 결과 반환: 벡터 데이터베이스에서는 검색 쿼리의 임베딩과 거리가 가까운 벡터를 찾아 반환

벡터 사이의 거리를 측정하는 다양한 방법이 있는데 일반적으로 유클리드 거리, 코사인 유사도, 점곱(dot product)을 가장 많이 활용   
### 12.1.2 벡터 데이터베이스 지형 파악하기
벡터 임베딩을 저장하고 검색하는 기능을 구현할 때 크게 아래와 같은 소프트웨어를 접함   
1. **벡터 라이브러리** - 메타의 Faiss, 스포티파이의 Annoy 와 같이 벡터를 저장하고 검색하는 핵심 기능을 구현   
2. **벡터 전용 데이터베이스** - 파인콘(Pinecone), 위비에이트(Weaviate)
3. **벡터 기능 추가 데이터베이스** - 일래스틱서치(Elasticsearch), PostgreSQL과 같이 기존의 데이터베이스에 벡터 저장과 검색 기능을 추가   
벡터 데이터베이스는 벡터 라이브러리와 다르게 아래와 같은 기능을 제공   
1. 메타 데이터의 저장 및 필터링 가능
2. 데이터의 백업 및 관리
3. 모니터링, 관련 AI 도구 등 에코시스템과의 통합
4. 데이터 보안과 엑세스 관리   

그림 12.7

고급 벡터 검색이 필요하고 워크로드가 큰 경우 그림 왼쪽의 벡터 전용 데이터베이스를 선택하는 것이 좋음   
벡터 데이터베이스에 대한 이해도가 있고 직접 오픈소스 서비스를 활용해 시스템을 구축할 수 있고 선호한다면 그림 왼쪽 위의 오픈소스 벡터 데이터베이스가 좋음   

## 12.2 벡터 데이터베이스 작동 원리
### 12.2.1 KNN 검색과 그 한계
**KNN(K-Nearest Neighbor)검색** - 검색하려는 벡터와 가장 가까운 K개 이웃 벡터를 찾는 검색 방식   
모든 데이터를 조사하기 때문에 정확하지만 모든 벡터를 조사하기 때문에 연산량이 데이터 수에 비례하게 늘어남   
벡터 검색을 위해서는 먼저 **인덱스**(관계형 데이터베이스의 테이블과 비슷한 레벨)를 만들어야 함   
인덱스를 벡터에 저장하는데, 이렇게 벡터를 저장하는 과정을 "**색인한다**"라고 함   
색인 단계에서는 인덱스의 메모리 사용량과 색인 시간이 중요하고 검색 단계에서는 검색 시간과 재현율이 중요   
**재현율** - 실제로 가장 가까운 K개의 정답 데이터 중 몇 개가 검색 결과로 반환됐는지 그 비율을 나타낸 값   
KKN 검색의 경우 재현율이 100%   

그림 12.8   

### 12.2.2 ANN 검색이란
**근사 최근접 이웃(Approximate Nearest Neighbor)검색** - 대용량 데이터셋에서 주어진 쿼리 항목과 가장 유사한 항목을 효율적으로 찾는 데 사용되는 기술   
대표적인 ANN 알고리즘   
1. **IVF(Inverted File Index)** - 검색 공간을 제한하기 위해 데이터셋 벡터들을 클러스터로 그룹화
2. **HNSW(Hierarchical Navigable Small World)** - 효율적인 ANN 검색을 위한 그래프 기반 인덱싱 구조   
HNSW가 가장 많이 활용되는 ANN 검색 알고리즘   
```
ANN 검색의 재현율 = (KNN으로 찾은 실제 가장 가까운 K개 중 ANN이 찾은 개수) / K
```

### 12.2.3 탐색 가능한 작은 세계(NSW)
HNSW의 그래프는 노드(node)와 간선(edge)로 이루어짐   
1. 노드 - 저장하는 데이터를 의미하고 벡터 데이터베이스에서는 벡터 임베딩이 노드
2. 간선 - 노드와 노드를 연결하는 선으로, 간선을 통해 서로 연결된 노드끼리만 탐색이 가능   

그림 12.9   

탐색 가능한 작은 세계 - 완전히 랜덤한 그래프와 완전히 규칙적인 그래프 사이에 '적당히 랜덤하게' 연결된 그래프 상태   
규칙적인 연결을 통해 정확한 탐색이 가능하면서도 랜덤한 성질을 통해 빠른 탐색이 가능   

그림 12.10   

하지만 랜덤으로 저장하다 보니 아래 그림과 같이 진입점에서 출발했을 때 찾으려는 검색 벡터(Q)와 가장 가까운 점(E)이 아닌 점 A에서 탐색을 멈추는 **지역 최솟값(local mininum)** 문제 발생   

그림 12.13   

### 12.2.4 계층 구조
연결 리스트(linked list) - 새로운 데이터를 추가하거나 삭제할 때 서로를 연결하는 주소 정보를 추가하거나 삭제하면 되기 때문에 데이터 추가/삭제가 자유롭지만 탐색을 할 때는 앞에서부터 순차적으로 확인해야 하기 때문에 탐색 속도가 느림   

그림 12.14   

아래 그림과 같이 데이터가 크기 순으로 정렬되어 있다면 레벨을 나누어 데이터를 듬성듬성 배치하고 탐색은 가장 위층부터 시작   

그림 12.15   

HNSW는 이런 계층 구조를 NSW에 접목해 벡터를 저장하는데 아래와 같은 기준으로 벡터를 저장   
1. 최대가 6인 주사위를 굴려서 6이 나오면 0,1,2층 모두 배치   
2. 주사위를 굴려서 4~5가 나오면 0,1층에 배치
3. 주사위를 굴려서 1,2,3이 나오면 0층에만 배치   

그림 12.16   

## 12.3 실습: HNSW 인덱스의 핵심 파라미터 이해하기
### 12.3.1 파라미터 m 이해하기
HNSW에서 파라미터 m은 추가하는 임베딩 벡터에 연결하는 간선의 수   
벡터에 연결되는 간선이 많을수록 그래프가 더 촘촘하게 연결되기 때문에 검색의 품질이 좋음   

예제 12.4   

표 12.2   

### 12.3.2 파라미터 ef_construction 이해하기
ef_construction은 M개의 가장 가까운 벡터를 선택할 후보군의 크기로, 이 값이 크면 더 많은 후보를 탐색하기 때문에 실제로 추가한 벡터와 가장 가까운 벡터를 선택할 가능성이 높음   

예제 12.5   

표 12.3   

### 12.3.3 파라미터 ef_search 이해하기
ef_search는 ef_construction이 색인 단계에서 후보군의 크기를 결정한 것과 동일하게 검색 단계에서 후보군의 크기를 결정   

예제 12.6   

표 12.4   

## 12.4 실습: 파인콘으로 벡터 검색 구현하기
### 12.4.1 파인콘 클라이언트 사용법
예제 12.8   
파인콘 인덱스에 저장할 수 있도록 tolist() 메서드를 사용해 형태를 변경   
예제 12.9   
예제 12.11   

### 12.4.2 라마인덱스에서 벡터 데이터베이스 변경하기
예제 12.13   

## 12.5 실습: 파인콘을 활용해 멀티 모달 검색 구현하기
### 12.5.1 데이터셋
예제 12.14   

### 12.5.2 실습 흐름
1. 원본 이미지와 세 가지 프롬프트로 생성한 3개의 합성 이미지를 비교   
2. 원본 이미지에 대응되는 '원본 프롬프트'를 입력   
3. 전체 프롬프트 텍스트를 텍스트 임베딩 모델로 저장한 벡터 데이터베이스에 원본 이미지를 이미지 임베딩 모델로 변환한 이미지 임베딩으로 검색해 찾은 '유사 프롬프트'를 사용해 이미지를 생성   

그림 12.19   

### 12.5.3 GPT-4o로 이미지 설명 생성하기
예제 12.15   

### 12.5.4 프롬프트 저장
아래 예제를 통해 프롬프트 임베딩을 저장하고 이미지 임베딩으로 검색할 인덱스를 생성   
예제 12.18   
아래 예제를 사용해 생성한 임베딩 벡터를 벡터 데이터베이스에 저장   
예제 12.20   

### 12.5.5 이미지 임베딩 검색
예제 12.21   

### 12.5.6 DALL-E 3로 이미지 생성
아래의 코드를 사용해 3개의 프롬프트에 대한 이미지를 생성
1. GPT-4o가 원본 이미지를 설명해서 작성한 GPT 설명 프롬프트로 이미지 생성
2. 원본 프롬프트를 사용해 이미지 생성
3. 이미지 임베딩으로 검색한 유사 프롬프트를 사용해 이미지 생성   

예제 12.24

출력결과는 아래와 같이 이미지 생성 파라미터에 따라 생성 결과가 달라지고 랜덤성이 있음   

그림 12.20   

# 13 LLM 운영하기
## 13.1 MLOps
MLOps(Machine Learning Operations) - 데브옵스(DevOps)의 개념을 머신러닝과 데이터 과학 분야로 확장한 방법론으로 데이터 수집, 전처리, 모델 학습, 평가, 배포, 모니터링 등 머신러닝 프로젝트의 전 과정을 자동화하고 효율화하는 것   

그림 13.1

MLOps는 특히 이전에 수행된 ML 워크플로를 그대로 반복했을 때 동일한 모델을 얻을 수 있는지 여부를 의미하는 재현성(reproducibility)를 보장하는 것이 매우 중요   

그림 13.2

### 13.1.1 데이터 관리
모델 학습을 위한 데이터 준비 과정에는 여러가지 중요한 의사결정이 포함되고 그 의사 결정에 따라 다양한 형태의 데이터셋이 생성   
포함시킬 데이터의 범위를 선택하고 어떤 전처리 방식을 포함시킬지, 특성 공학을 통해 어떤 특성을 추가할지에 따라 학습 데이터셋이 달라짐   

그림 13.3   

모델 학습 결과를 재현하기 위해서는 데이터셋의 버전을 관리하고 어떤 학습 데이터셋으로 모델을 학습시켰는지 기록해야 함   

### 13.1.2 실험 관리
머신러닝 모델을 학습시킬 때는 어떤 모델을 사용할지 결정해야 함   

그림 13.4   

### 13.1.3 모델 저장소
MLOps에서 모델 저장소(model registry)는 머신러닝 모델을 체계적으로 관리하고 버전 제어하는 데 필수   
여러 머신러닝 파이프라인에서 다양한 실험을 통해 여러 버전의 모델이 생성되는데, 이를 활용하면 다양한 모델을 통합해서 관리할 수 있음   

그림 13.5   

### 13.1.4 모델 모니터링
머신러닝 모델은 학습 데이터를 통해 학습한 패턴을 바탕으로 예측을 수행하기 때문에 정상적으로 요청에 응답하고 있더라도 엉뚱한 값을 반환한 것은 아닌지 확인   

## 13.2 LLMOps는 무엇이 다를까?
### 13.2.1 상업용 모델과 오픈소스 모델 선택하기
LLMOps에서는 MLOps보다 훨씬 크고 다양한 일을 할 수 있는 모델을 다룬다는 점에서 큰 차이   

표 13.1   

### 13.2.2 모델 최적화 방법의 변화
LLMOps에서 다루는 LLM은 모델의 크기가 크기 때문에 일반적으로 사전 학습시키는 경우는 거의 없음   
오픈소스 모델을 선택했다면 미세 조정을 자유롭게 수행할 수 있지만, 상업용 모델을 선택했다면 미세 조정 기능을 지원하는 모델만 제한적으로 미세 조정할 수 있음   

표 13.2   

LLMOps에서 다루는 언어 모델은 모델의 크기가 크고 처음부터 학습시킬 때 들어가는 계산량이 크기 때문에 일반적으로 사전 학습하지 않고 사전 학습된 모델을 가져와 미세 조정하는 전이 학습을 기본으로 사용   
모델 개발 과정에서 학습할 때 설정한 하이퍼파라미터를 기록해 두고 이후 동일한 성능의 모델을 다시 만들 수 있도록 관리   

### 13.2.3 LLM 평가의 어려움
LLM은 다양한 작업이 가능하기 때문에 특정 작업의 성능 평가 방식으로 모두 평가할 수 없고 프롬프트에 따라 성능이 달라지기도 해서 명확한 기준을 잡기 어려움   

## 13.3 LLM 평가하기
### 13.3.1 정량적 지표
텍스트 생성 작업을 평가할 때 사용할 수 있는 대표적인 세 가지 정량 지표   
1. BLEU(Bilingual Evaluation Understudy Score) - 기계 번역 결과와 사람이 번역한 결과의 유사도를 측정하여 평가   
2. ROUGE(Recall-Oriented Understudy for Gisting Evaluation)- 모델이 생성한 요약문과 사람이 작성한 참조 요약문 사이의 n그램 중복도를 재현율 관점에서 측정   
3. 펄플렉시티(Perplexity) - 모델이 새로운 단어를 생성할 때의 불확실성을 수치화한 것으로, 값이 낮을수록 모델의 예측 성능이 우수하다는 의미   

세 가지 정량 지표 모두 빠르게 언어 모델의 성능을 평가할 수 있다는 장점이 있지만 문장의 의미, 문법, 유창성 등 질적인 측면의 평가에는 한계가 있고 실제 사람의 주관적 판단과 불일치하는 경우가 많음   

### 13.3.2 벤치마크 데이터셋을 활용한 평가
벤치마크 데이터셋 - 다양한 모델의 성능을 비교하기 위해 공통으로 사용하는 데이터셋, 대표적으로 (ARC, HellaSwag, MMLU 등)   

표 13.3   

W&B에서 새로운 한국어 LLM 리더보드인 호랑이(Horangi)가 공개   
문장의 생성 확률이 아니라 실제로 생성한 텍스트 결과가 A,B,C,D와 같이 정답과 일치하는지를 비교해 성능을 평가   

### 13.3.3 사람이 직접 평가하는 방식   
사람이 직접 평가하는 방식은 언어의 유창성과 같이 정량적인 지표로 평가하기 어려운 사항을 평가할 수 있다는 장점이 있지만 시간이 오래 걸리고 비용이 많이 든다는 단점이 있음   

### 13.3.4 LLM을 통한 평가
표 13.4   
첫 번째 턴에서 하나의 요청을 하고 응답 이후에 다시 두 번째 요청을 함   
어러 턴에 걸쳐 LLM이 사용자의 요구사항에 맞춰 대응하는지 확인하기 위해서임   

사람과 LLM의 평가가 80% 이상 일치했기 때문에 사람이 직접 평가할 때 드는 시간과 비용을 생각하면 LLM을 활용해 비교적 적은 비용으로 빠르고 정확하게 평가를 수행해서 사람이 직접 평가하는 양을 줄일 수 있음   

### 13.3.5 RAG 평가
그림 13.9   
1. 신뢰성(faithfulness) - 생성된 응답이 검색된 맥락 데이터에 얼마나 사실적으로 부합하는 지 평가   
2. 답변 관련성(answer relevancy) - 생성된 답변이 요청과 얼마나 관련성 있는지 평가
3. 맥락 관련성(context relevancy) - 검색 결과인 맥락 데이터가 요청과 얼마나 관련 있는지 평가   

# 14 멀티 모달 LLM