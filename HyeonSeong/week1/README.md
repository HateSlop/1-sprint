# LLM을 활용한 실전 AI 애플리케이션 개발
------------------
# 1.LLM 지도

## 1.1 딥러닝과 언어 모델링
**LLM(Large Language Model)** - 딥러닝에 기반
사람의 언어를 컴퓨터가 이해하고 생성할 수 있도록 연구하는 **자연어 처리(natural language processing)**   
**언어 모델** - 다음에 올 단어가 무엇일지 예측하면서 문장을 하나씩 만들어 가는 방식으로 텍스트 생성

### 1.1.1 데이터의 특징을 스스로 추출하는 딥러닝   
문제를 해결하는 방법   
>문제의 유형에 따라 일반적으로 사용되는 모델을 준비   
>풀고자 하는 문제에 대한 학습 데이터 준비   
>학습 데이터를 반복적으로 모델에 입력   

딥러닝 / 머신러닝 - 데이터의 특징을 누가 뽑는가?   
머신러닝은 데이터의 특징을 연구자 또는 개발자가 추출 / 딥러닝은 모델이 스스로 데이터의 특징을 찾고 분류   

### 1.1.2 임베딩: 딥러닝 모델이 데이터를 표현하는 방식   
**임베딩** - 데이터의 의미와 특징을 포착해 숫자의 집합으로 표현하는 것   
거리를 계산할 수 있기 때문에 다음과 같은 작업에 적합 

    검색 및 추천: 검색어와 관련이 있는 상품을 추천
    클러스터링및 분류: 유사하고 관련이 있는 데이터를 하나로 분류
    이상치 탐지: 나머지 데이터와 거리가 먼 데이터는 이상치로 표현   

그림 1.6

### 1.1.3 언어 모델링: 딥러닝 모델의 언어 학습법   
**전이 학습** - 하나의 문제를 해결하는 과정에서 얻은 지식과 정보를 다룬 문제를 풀 때 사용하는 방식   
대량의 데이터로 모델을 학습시키는 **사전학습** / 특정한 문제를 해결하기 위한 데이터로 추가 학습하는 **미세 조정**   
특정한 데이터만으로 학습한 모델보다 사전 학습 모델의 일부를 가져와 활용했을 때 더 성능이 좋음   
그림 1.9   
순환신경망(Recurrent Neural Network)에서 언어 모델링이 사전 학습 과제로 적합   

## 1.2 언어 모델이 챗GPT가 되기까지
### 1.2.1 RNN에서 트랜스포머 아키택처로   
RNN - 입력하는 텍스트를 순차적으로 처리해서 다음 단어를 예측   
그림 1.12   
트랜스포머 아키텍처는 순차적인 처리 방식이 아닌, 맥락을 모두 참조하는 어탠션(attention)연산을 사용   
그림 1.14   
맥락을 압축하지 않고 그대로 활용하기 때문에 성능은 높아지는 대신 무겁고 비효율적인 연산을 사용   

