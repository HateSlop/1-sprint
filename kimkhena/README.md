# LLM을 활용한 실전 AI 애플리케이션 개발

## 1.1 딥러닝과 언어 모델링

**LLM (Large Language Models)**은 딥러닝 기반의 언어 모델로, 자연어 처리 분야(NLP)에 속한다.
* 딥러닝 - 인간의 두뇌에 영감을 받아 만들어진 신경망. 정형데이터, 비정형데이터 인식이 높다.
* 자연어 처리 분야 - 사람의 언어를 컴퓨터가 이해하고 생성 할 수 있는 연구 분야.

주요 특징:
- **정형/비정형 데이터**에서 패턴 인식 성능이 높음
- **딥러닝 모델**을 통해 자율적인 학습이 가능함
- **임베딩** 기술을 사용하여 데이터를 숫자형 벡터로 변환함

### 1.1.1 데이터의 특징을 스스로 추출하는 딥러닝
**딥러닝 문제 해결 방법**
1) 문제 유형에 맞는 일반적으로 사용되는 모델 준비  
2) 풀고자 하는 학습 데이터를 준비  
3) 학습 데이터를 반복적으로 모델에 입력하여 학습 

딥러닝은 머신러닝과 반대로 상당한 양의 **학습데이터**를 제공하기만 하면 시스템이 **자율적으로 학습** 할 수 있다. 머신런닝은 개발자가 데이터의 ‘특징’을 직접 찾고 입력해야 한다.

### 1.1.2 임베딩: 딥러닝 모델이 데이터를 표현하는 방식

**임베딩(embedding)**은 데이터의 의미와 특직을 포착하여 숫자의 집합으로 변환시킨다.
데이터를 임베딩을 하여 숫자로 표현 한 후, 데이터의 유사함을 거리로 측정이 가능하다. (ex:MBTI)

임베딩의 활용:
- **검색 및 추천**: 검색어와 관련있는 상품 추천
- **클러스터링 및 분류**: 유사 데이터를 묶음
- **이상치 탐지**: 나머지 데이터와 먼 비정상적 데이터를 탐지

단어 임베딩(word embedding) - 단어를 임베딩으로 변환하는 것.
일반적으로 수십-수만개의 숫자로 표현한다. 딥러닝 모델이 데이터 특징을 알아서 추출하기 때문에 각 숫자의 의미를 알기 어렵다. 숫자 집합 을 안다면 단어의 의미를 알 수 있다.


### 1.1.3 언어 모델링: 딥러닝 모델의 언어 학습법

**언어 모델링** - 모델이 입력받은 텍스트의 다음 단어를 예측해 텍스트를 생성하는 방식

**전이 학습** - 하나의 문제를 해결하는 과정에서얻은 지식을 다른 문제에 활용하는 방식 (딥러닝 분야에서 애용)
+ 사전 학습 - 대량의 데이터로 모델을 학습
+ 미세 조정 - 특정 데이터를 해결하기 위한 추가 학습 (이 학습 모델을 사용하는 과제를 downtream 과제라도 부른다)

![전이 학습 방식](https://github.com/user-attachments/assets/8afb45e7-5d8b-4247-9d20-98d79d9ace70)
본체 - 이미지넷으로 학습한 모델 (점이나 선같은 기본적인 이미지 특징을 이미 파악해 놓은 데이터셋)
___ 분류헤드 - 해결하려는 이미지의 데이터셋을 추가 학습

---

## 1.2 언어 모델이 CHAT GPT가 되기 까지

### 1.2.1 RNN에서 트랜스포머 아키텍처(구조)로

**시퀀스 데이터** - 순서대로 정열된 데이터의 연속. 텍스트, 오디오, 시계열 데이터 등이 이에 해당하며, 이를 처리하기 위해 **RNN** 또는 **트랜스포머**를 사용한다.

**RNN(Recurrent Neural Network)** - 트랜스포머 아키텍처를 사용하기 전 텍스트를 생성하기위해 사용되었던 모델. 정보가 쌓이면서 텍스트 맥락이 압축된다. 단점: 앞에 있는 단어들의 의미가 희석된다
![입력을 순차적으로 처리하는 RNN 모델의 방식](https://github.com/user-attachments/assets/8afb45e7-5d8b-4247-9d20-98d79d9ace70)

**트랜스포머 아키텍쳐** - 문장 속 단어와 같은 순차 데이터 내의 관계를 추적해 맥락과 의미를 학습하는 신경망. 맥락 데이터를 모두 활용한다. 무겁고 비효율적인 연산을 한다. 그러나 RNN의 단점(느린 학습 속도, 긴 시퀀스 처리 성능 저하)을 극복하고 병렬 연산을 가능하다.  
![트랜스포머 아키텍쳐의 어텐션 연산](https://github.com/user-attachments/assets/8afb45e7-5d8b-4247-9d20-98d79d9ace70)

* 결론: RRN은 효율적이지만 성능이 낮다. 트랜스포머 아키텍쳐는 성능이 높지만 효율이 낮다. 하지만 병렬처리를 통해 학습속도를 높일 수 있어 대부분 LLM이 트랜스포머 아키텍처를 사용 한다.

### 1.2.2 GPT 시리즈로 보는 모델 크기와 성능의 관계 

모델 데이터가 많아질 수록 최종 모델의 성능이 높아진다. 학습하는 과정 중 
학습 데이터의 공통되고 중유한 패턴을 남겨 손실 압축한다. 그래서 학습데이터 모델 크기가 최대 모델 크기보다 많을 수 없다.

### 1.2.3 Chat GPT의 등장

**지도미세조정** - 언어 모델링으로 학습한 언어모델을 *지시 데이터 셋*으로
추가 학습한다. ( 데이터셋을 위해 OpenAi에서는 따로 작업자에게 LLM이 받을법한 질문과 답을 작성해야 했다. 그 결과 사용자의 요청에 맞춰 응답하는 모델을 만들 수 있었다)
지시 데이터 셋 - 사용자가 요청한 사항과 그이 대한 적절한 응답을 정리한 데이터 셋

**RLHF(reinforcement Learning from Human Feedback)** - 사람의 피드백을 활용한 강화 학습. 선호 데이터셋으로( 두가지 선택 중 사용자가 더 선호하는 답변을 정리한 데이터셋) 답변을 평가하는 리워드 모델을 만들어 LLM이 높은 점수
를 받게 추가 학습한다.

**지도 미세 조정** 과 **RLHF** 라는 기술 덕분에 사용자의 말을 이어서 작성하는 능력 뿐만이 아니라 사용자의 요청을 해결하는 능력이 생겼다.

##1.3 LLM 애플리케이션의 시대가 열린다

### 1.3.1 지식 사용법을 획기적으로 바꾼 LLM 
LLM은 다른 자연어 처리 모델과 다르게 언어를 *이해*하는 것 뿐만이 아니라 결과를 언어로 *생성*해야 하는 능력이 뛰어나다.

### 1.3.2 sLLM: 더 작고 효율적인 모델 만들기 

기업들이 LLM을 크게 두가지로 활용한다:
**상업용 API**: 장점: 모델이 크다, 텍스트 생성 능력이 뛰어나다. 단점: 추가 학습이 안된다. 여러 모델이 뒤섞여 있어 특정분야를 잘 모를 수 있다
**오픈소스 LLM**: 장점: 특정 도메인 데이터나 작업에 높은 성능을 보여준다. 단점: 모델 크기가 작다. 이를 **sLLM**이라고 한다

### 1.3.4 LLM의 환각 현상을 대처하는 검색 증각 생성(RAG) 기술
LLM은 정보가 사실인지, 거짓인지 판단을 못한다. 그래서 잘못된 정보가 실제로 존재하지 않는 정보를 만드는 **‘환각 현상’**이 생긴다.
이를 해결하기 위해 **RAG**이라는(응답을 생성하기 전에 학습데이터에 신뢰 할 수 있는 지식 베이스를 참조하게 하는 기술) 기술을 사용한다.

## LLM의 미래: 인식과 행동의 확장
AI분야는 다양한 방향으로 연구가 진행되고 발전해 나가고 있다. 

- 멀티모달 LLM: 다양한 형식의 데이터(ex:오디노,비디오)를 입력으로 받고 여러 형태로 출력 할 수 있는 LLM 모델
- 에이전트: 텍스트 생성 능력을 사용해 계획을 세우거나 늬사결정을 내리고 필요한행동을 수행하는 LLM 모델
- 트랜스포머 아키텍쳐보다 성능이 높고 효율적인 아키텍쳐 연구도 진행하고 있다.  

---

# 2. LLM의 중추, 트랜스포머 아키텍처 살펴보기

## 2.1 트랜스포머 아키텍처란

**RRN**의 모델 구조는 모델의 한번에 한 토큰씩 입력을 받아 추출을 한다. 이 출력을 다시 다음 입력 토큰과 함께 RRN에 입력해야 하기 때문에 
**비효율적**이다. (사람이 글을 읽는 것과 비슷) (학습속도가 느려지고 입력이 길어지면 먼저 입력한 토큰의 정보가 희석되면서 성능이 떨어진다.)

![RRN 모델 구조](../static/img_2.2_텍스트_임베딩.png)
> RRN 모델 구조

이를 해결하기 위해 트랜스포머는 **셀프 어텐션(self attention)**을 사용한다. 이는 인코더와 디코더에 가장 중요한 부분이다. 
셀프 어텐션은 입력된 문장 내의 각 단어가 서로 어떤 관계인지 계산해서 각 단어의 표현을 조정한다.

트랜스포머 장점:
- 확장성: 더 깊은 모델을 만들어도 학습이 잘된다. 
- 효율성: 학습할때 병렬연산이 가능하기 때문에 학습 시간이 단축된다. 
- 더 긴 입력처리: 입력이 길어져도 성능이 거의 떨어지지 않는다.

트랜스포머 아키텍쳐는 크게 **인코더**(언어를 이해하는 역할)와 **디코더**(언어를 생성하는 역할)로 나뉜다. 
- 인코더와 디코더 모두 처음에 모델을 토큰화 후 임베딩 층을 통해 임베딩(숫자 집합) 으로 변환하고 위치 인코딩(positional encoding)층에서 문장의 위치 정보를 더한다
- 인코더에서 층 정규화(layer normalization), 멀티 헤드 어텐션(multi-head attention), 피드 포워드(feed forward)층을 거쳐 디코더로 전달한다.
- 디코더에서 층 정규화(layer normalization), 멀티 헤드 어텐션(multi-head attention)을 수행하면서 크로스 어텐션 연산을 한다
- 디코더와 인코더의 출력을 종합해서 피드 포워드 층을 거쳐 결과를 생산한다.

![트랜스포머 아키텍쳐를 구성하는 인코더와 디코더](../static/img_2.2_텍스트_임베딩.png)
> 트랜스포머 아키텍쳐를 구성하는 인코더와 디코더

## 2.2 텍스트를 임베딩으로 변환하기
컴퓨터가 텍스트를 이해하고 계산 하기 위해 텍스트를 숫자 형식으로 바꿔야 한다.
1) **토큰화(tokenization)** 수행: 텍스트를 적절한 단위로 잘라 숫자형 ID를 부여한다
2) 토큰 ID를 **토큰 임베딩 층**을 통해 여러 숫자의 집합인 **토큰 임베딩**으로 변환한다.
3) **위치 인코딩**을 통해 토큰의 위치 정보를 담고 있는 임베딩을 추가 해 최종적으로 모델에 입력 할 임베딩을 만든다. 

![텍스트에서 임베딩으로 변환하는 과정](../static/img_2.2_텍스트_임베딩.png)
> 텍스트에서 임베딩으로 변환하는 과정

### 2.2.1 토큰화 

**토큰화** - 텍스트를 적절한 단위로 나누고 ID를 부여하는 것
**서브워드 토큰화** - 자주 나오는 단어일수록 그대로 유지하여 토큰화

**토큰화 방법:**
1) 문장을 단위로 자른다.(한국어는 자모, 음절, 단어단위로 자를 수 있다.)
2) 토큰 딕셔너리를 만든다.(각각 단어에게 순서대로 토큰을 부여한다) (str2idx)
3) ID 딕셔너리를 만든다. (ID를 순서대로 각각 단어에게 부여된다) (idx2str)
4) ID 딕셔너리에서 토큰을 토큰 딕셔너리에서 가져온 토큰 ID로 변환한다.

![토큰화 방식](../static/img_2.2_텍스트_임베딩.png)
> 등장빈도와 단위에 따른 서브워드 토큰화 방식


### 2.2.2 토큰 임베딩으로 변환하기
딥러닝 모델이 토큰 사이에 관계를 숫자로 계산해야 한다. 토큰ID는 숫자 하나일뿐이라서 의미를 못 담는다. 그래서 1.1.2에서 MBTI예시처럼 임베딩을 만들어야 한다. 
**임베딩** - 데0이터의 의미를 담아 숫자 집합으로 변환하는 것

이를 위해 PyTorch에 제공하는 no.Embedding 클래스를 사용해야 한다.
1) 임베딩 벡터의 차원을 정한다. (embedding_dim)(ex: 3차원: [0.0, 0.0, 0.0],[0.2,0.4,0,1]…)
2) 차원에 임베딩을 생성하는 임베딩 레이어(embed_layer)를 정한다. 이는 토큰 아이디 집합의 크기에 따른다.
3) 입력 토큰을 임베딩 층을 통해 임베딩으로 변환한다.

위 과정을 거친다고 해서 토큰의 의미가 담겨 벡터로 변환되는 것은 아니다. 임베딩 층이 단어의 의미를 담기 위해서는 딥러닝 모델이 학습 데이터로 훈련되어야 한다.
딥러닝은 머신러닝과 달리 직접 모델이 특정 작업을 잘 수행하도록 학습하는 과정에서 점점 토큰의 의미를 잘 담는 임베딩을 같이 학습하게 된다.

### 2.2.3 위치 인코딩

위치 인코딩이 필요한 이유: 트랜스포머 아키텍쳐에서 RRN과 달리 모든 토큰 입력을 동시에 처리하는데, 그 과정에서 **순서 정보를 따로 추가**하기 위해 존재한다.

**절대적 위치 인코딩(absolute position encoding)**- 위치 인덱스 자체를 위치 임베딩으로 사용한다.
장점:간단하게 구현이 가능하다. 단점: 토큰과 토큰 사이에 상대적 위치 정보를 활용 못한다. 긴 텍스트를 추론하는 경우 성능이 떨어진다. 
상대적 위치 인코딩 (relative position encoding) - 절대적 위치 인코딩 단점을 보완한다. 

트랜스포머가 있는 지금은 모든 입력 토큰을 동일하게 처리하시 떄문에 위치 정보를 더해주는 역할만 한다.

*(인코딩, 임베딩 차이가 뭐지???)*

## 2.3 어텐션 이해하기

### 2.3.1 사람이 글을 읽는 방법과 어텐션

단어의 뜻을 찾으려면 단어와 단어 사이에 관계를 계산 해 그 값에 따라 관련이 깊은 단어와 깊지 않는 단어를 필터링 한다. **어텐션**이 이 기능을 수행한다.

어텐션은 문장에서 각 단어 간의 관련성을 학습하는 메커니즘입니다. **쿼리(Query)**, **키(Key)**, **값(Value)** 세 요소를 통해 작동한다.

### 2.3.2 쿼리, 키, 값 이해하기
검색 분야에서의 비유: 
- **쿼리**- 검색어 (단어)
- **키**- 문서 제목,본문,저자 (문장 속 각 단어)
- **값**- 키의 문서 (단어가 전달하려는 정보) (이것을 검색하면서 원하는 것이다)

쿼리와 키 관계 계산 방법: 쿼리와 키를 **토큰 임베딩**으로 변환하여 관계를 계산해서 관련도를 계산한다. 
그러나 이러면 같은 단어끼리(ex:파리(Paris,fly)) 임베딩이 똑같아서 관련도가 크게 계산된다. 또한 간접적인 관련성이 반영되기 어렵다.(ex: ‘나는‘, 
‘최근’은 ‘다녀왔다’토큰에 누가,언제를 나타내는 문법관계이지만 토큰 자체로 봤을때는 관련성을 찾기 어렵다.)
이를 해결하기 위해 **가중치**(Wq,Wk)를 도입했다. (딥러닝에서는 어떤 기능을 잘하고 싶을 때 가중치를 도입하고 학습단계에서 업데이트 되게 한다.)
가중치를 통해 토큰과 토큰 사이에 관계를 계산하는 능력을 학습시킨다.

스케일 점곱 방식의 어텐션 연산 코드:
1)가중치 계산
1.1) PyTorch에서 제공하는 nn.Linear 층을 사용해 쿼리,키,값 각각의 가중치를 생성한다. 
1.2) 입력 임베딩(input_embedding)을 선형 층에 통과시켜 쿼리, 키, 값을 생성한다.
2)쿼리, 키, 값 관계 를 계산한 새로운 단어 벡터 생성 
2.1) 쿼리와 키를 곱해 두 단어의 관련성을 계산한다. (분산이 커지는 것을 방지하기 위해 임베딩 차원 수의(dim_k)의 제곱근으로 나눈다.)
2.2) 그 값들을 스포트맥스(softmax)를 취해 0-1사이에 값으로 바꿔서 가중치로 바꾼다.
2.3) 가중치와 값을 곱해 입력은 동일하면서 주변 토큰과의 관련도에 따라 새로운 토큰 임베딩을 반환한다
이로서 트랜스포머에서는 쿼리,키,값을 토큰 임베딩 하여 가중치를 통해 변환한다. 이 세가지 가중치를 통해 토큰과 토큰 사이에 관계를 계산해 적절한 주변 맥락을 반영하는 학습을 시킨다.

![가중치 계산](../static/img_2.2_텍스트_임베딩.png)
> 가중치 계산

![값 벡터를 가중합해서 새로운 단어 벡터 생성](../static/img_2.2_텍스트_임베딩.png)
> 값 벡터를 가중합해서 새로운 단어 벡터 생성

### 2.3.4 멀티 헤드 어텐션 

**멀티 헤드 어텐션** - 어텐션 연산을 동시에 수행하는 어텐션 방식. 이를 통해 토큰 사이에 다양한 관점에서 단어 간에 관계를 학습 할 수 있다.
여러개에 어텐션을 동시에 사용하여 문맥 이해에 도움이 된다.

멀티 헤드 어텐션 코드:
1) 쿼리,키,값의 각각 선형층을 n_head(헤드의 수)로 나눠서 각각 변환 후 입력과 같은 형태로 변환한다.
2) 쿼리, 키, 값의 각각 어텐션 계산한다
3) 어텐션 결과를 다시 원래 현태로 변환한다
4) 마지막으로 선형 층을 통과시키고 최종 어텐션 결과를 반환한다.
