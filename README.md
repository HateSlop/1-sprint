# 1. LLM 지도

## 1.1 챗GPT의 등장과 LLM
2022년 말, 챗GPT가 등장하면서 대규모 언어 모델(LLM)이 세상을 뒤흔들었다. 기존의 언어 모델과는 달리, 챗GPT는 다음 단어를 확률적으로 예측하고 그 예측을 바탕으로 문장을 생성하는 방식으로 다양한 작업에서 뛰어난 성능을 보여준다. 이는 텍스트를 단순히 처리하는 기존 모델과 달리 사람과 자연스러운 대화를 할 수 있을 정도로 발전했다.

챗GPT의 혁신적인 성능에도 불구하고 그 동작 원리는 매우 단순한 방식에서 시작된다. 주어진 입력에서 다음에 올 적절한 단어를 예측하고, 그 단어를 입력에 추가해 문장이 완성될 때까지 반복한다.

## 1.2 딥러닝과 언어 모델링
LLM은 딥러닝 기술에 기반을 두고 있으며, 딥러닝은 신경망을 통해 데이터를 학습하는 기계 학습의 한 분야이다. 딥러닝은 텍스트와 이미지 같은 비정형 데이터에서 뛰어난 성능을 보여주며, 자연어 처리(NLP) 분야에서 텍스트를 생성하는 자연어 생성(NLG)을 연구하는 핵심 기술로 자리 잡았다.

2013년 구글의 **Word2Vec** 모델 발표를 시작으로, 2017년에는 **트랜스포머(Transformer)** 아키텍처가 등장하여 기존의 RNN을 대체하였으며, 2018년에는 OpenAI의 **GPT-1** 모델이 공개되었다. 이를 통해 언어 모델의 성능이 비약적으로 향상되었다.

### 1.2.1 임베딩
딥러닝 모델은 데이터를 처리하기 위해 임베딩(embedding)이라는 방식을 사용한다. 임베딩은 데이터를 숫자로 표현하여, 데이터 간의 유사성을 계산하거나 클러스터링에 활용할 수 있다. 대표적인 예로 **Word2Vec** 모델이 있다. 이를 통해 텍스트 데이터가 숫자의 집합으로 변환되고, 텍스트 간의 유사도를 기반으로 다양한 작업을 수행할 수 있다.

### 1.2.2 전이 학습(Transfer Learning)
전이 학습은 대량의 데이터로 학습된 모델을 다른 과제에 맞게 추가 학습하는 방식이다. 이 방식은 특히 학습 데이터가 적을 때 유용하다. LLM은 이 전이 학습 방식을 사용해 사전 학습된 모델을 특정 작업에 맞게 미세 조정하여 성능을 높인다.

## 1.3 트랜스포머 아키텍처와 GPT 시리즈
### 1.3.1 트랜스포머 아키텍처
2017년에 공개된 트랜스포머 아키텍처는 이전의 RNN을 대체하며, 텍스트 처리 성능을 크게 향상시켰다. 트랜스포머는 RNN과 달리, 입력 데이터를 순차적으로 처리하는 대신 모든 입력 데이터 간의 관계를 동시에 고려한다. 이를 통해 더 긴 문장을 처리할 때에도 성능 저하가 발생하지 않으며, 병렬 처리가 가능하여 학습 속도가 크게 향상된다.

### 1.3.2 GPT 시리즈
- **GPT-1 (2018년)**: 1억 1,700만 개의 파라미터를 사용한 첫 번째 모델로, 트랜스포머 아키텍처를 기반으로 개발되었다.
- **GPT-2 (2019년)**: 15억 개의 파라미터로, 모델 크기가 크게 확장되었다.
- **GPT-3 (2020년)**: 1,750억 개의 파라미터를 가진 모델로, 언어 생성 능력이 사람과 유사한 수준으로 발전했다.

## 1.4 챗GPT의 혁신과 RLHF
**챗GPT**는 기존 GPT 모델에 **인간 피드백을 활용한 강화 학습(RLHF)** 기술을 도입하여, 단순히 텍스트를 생성하는 것을 넘어 사용자의 요청에 맞춘 답변을 생성할 수 있게 되었다. RLHF는 사용자의 선호를 반영하여 더 나은 답변을 생성할 수 있도록 모델을 학습시키는 기술이다.

이 기술을 통해 LLM은 사용자의 요청에 맞춰 더욱 정교한 답변을 제공하며, 이를 정렬(alignment)이라고 부른다. 정렬을 통해 LLM이 사용자에게 도움이 되는 정보를 제공하는 방향으로 학습된다.

## 1.5 LLM 애플리케이션의 시대
챗GPT의 성공 이후, 많은 조직에서 LLM을 활용한 애플리케이션을 개발하고 있다. 이 장에서는 대표적인 두 가지 기술, **sLLM (Small LLM)**과 **RAG (Retrieval Augmented Generation)**을 간략히 소개한다.

- **sLLM**: 특정 작업이나 도메인에 맞게 추가 학습된 작은 모델로, 적은 파라미터로도 높은 성능을 발휘한다.
- **RAG**: 검색 증강 생성 기술로, LLM이 환각 현상을 일으키는 문제를 해결하기 위해 외부 지식을 검색하여 응답의 정확도를 높인다.

## 1.6 LLM의 확장: 멀티모달과 에이전트
LLM은 텍스트 처리 능력을 넘어 **멀티모달(Multi-modal)** 데이터 처리로 확장되고 있다. 멀티모달 LLM은 텍스트뿐만 아니라 이미지, 비디오, 오디오 등의 데이터를 처리할 수 있으며, 다양한 작업에서 활용될 수 있다.

또한, LLM을 활용한 **에이전트(Agent)** 연구도 활발히 진행 중이다. LLM은 텍스트 생성뿐만 아니라 의사결정과 계획 수립에도 활용될 수 있으며, **AutoGPT**와 같은 자동화 시스템이 이에 대한 대표적인 예시이다.


# 2. LLM의 중추, 트랜스포머 아키텍처 살펴보기

## 2.1 트랜스포머 아키텍처란
트랜스포머 아키텍처는 2017년 구글에서 발표된 모델로, 기존의 RNN(Recurrent Neural Network)의 한계를 극복하기 위해 개발되었다. 순차적으로 데이터를 처리하지 않고, 셀프 어텐션(Self-Attention) 메커니즘을 통해 병렬 연산이 가능하며, 더 긴 입력 데이터도 효율적으로 처리할 수 있다.

## 2.2 텍스트를 임베딩으로 변환하기
임베딩은 텍스트 데이터를 모델이 이해할 수 있는 숫자형 데이터로 변환하는 과정이다. 텍스트는 토큰화 과정을 통해 나누어진 뒤, 임베딩 층을 통해 숫자로 변환된다. 여기에 위치 인코딩(Positional Encoding)을 더하여 순서를 반영한 임베딩을 생성한다.

## 2.3 어텐션 이해하기
어텐션 메커니즘은 입력된 문장에서 중요한 단어들 사이의 관계를 파악하는 과정이다. 트랜스포머의 핵심은 이 어텐션 메커니즘을 활용하여 모든 입력 단어 간의 상관관계를 계산하는 것이다.

### 2.3.1 쿼리, 키, 값
- **쿼리(Query)**: 현재 처리 중인 단어
- **키(Key)**: 비교 대상이 되는 단어
- **값(Value)**: 키에 해당하는 단어의 임베딩 값
쿼리와 키의 관계를 계산하여 값에 반영하는 방식으로 동작한다.

## 2.4 정규화와 피드포워드 층
정규화는 입력 데이터의 분포를 일정하게 유지하기 위해 사용되며, 피드포워드 층은 입력 데이터의 특징을 학습하는 역할을 한다. 트랜스포머 아키텍처에서 정규화는 각 층의 입력을 안정적으로 만들어 준다.

## 2.5 인코더
인코더는 입력 텍스트를 이해하는 역할을 한다. 트랜스포머 인코더는 멀티 헤드 어텐션과 피드포워드 층을 반복적으로 적용하여 입력 데이터를 처리한다. 인코더는 텍스트의 문맥을 파악하여 디코더에 필요한 정보를 전달한다.

## 2.6 디코더
디코더는 인코더에서 전달된 정보를 바탕으로 출력 텍스트를 생성하는 역할을 한다. 인코더의 출력을 받아 다시 멀티 헤드 어텐션과 피드포워드 층을 거쳐 최종 출력을 생성한다.

## 2.7 BERT, GPT, T5 등 트랜스포머를 활용한 아키텍처
트랜스포머 아키텍처를 기반으로 한 대표적인 모델로는 BERT, GPT, T5가 있다. 
- **BERT**: 양방향으로 문맥을 학습하며, 텍스트 이해에 최적화된 모델.
- **GPT**: 텍스트 생성에 최적화된 모델로, 주로 생성 작업에 사용됨.
- **T5**: 텍스트 변환 작업에 최적화된 모델로, 다양한 자연어 처리 작업에 활용됨.

## 2.8 주요 사전 학습 메커니즘
트랜스포머 기반 모델을 학습시키기 위해서는 사전 학습(Pre-training)과 미세 조정(Fine-tuning)이 필요하다. 대규모 데이터를 통해 모델이 언어의 일반적인 패턴을 학습하고, 이후 특정 작업에 맞게 미세 조정된다.


# 3. 트랜스포머 모델을 다루기 위한 허깅페이스 트랜스포머 라이브러리

## 3.1 허깅페이스 트랜스포머란
허깅페이스 트랜스포머는 다양한 트랜스포머 모델을 통일된 인터페이스로 사용할 수 있도록 지원하는 오픈소스 라이브러리이다. 이를 통해 서로 다른 모델을 동일한 방식으로 쉽게 불러오고 사용할 수 있다. 트랜스포머 모델을 학습하고 추론하는 과정을 간소화해 연구와 개발의 속도를 높이는 데 기여하고 있다.

## 3.2 허깅페이스 허브 탐색하기
허깅페이스 허브는 사전 학습된 다양한 모델과 데이터셋을 제공하는 온라인 플랫폼이다. 사용자는 자신이 원하는 모델이나 데이터셋을 허브에서 검색하고 활용할 수 있으며, 자신이 만든 모델이나 데이터셋을 공유할 수도 있다. 

### 3.2.1 모델 허브
모델 허브에서는 NLP뿐만 아니라 컴퓨터 비전, 오디오 처리 등 다양한 작업을 위한 모델을 제공하며, 각 모델은 작업 유형, 언어, 라이선스 등을 기준으로 분류되어 있다.

## 3.3 허깅페이스 라이브러리 사용법 익히기
허깅페이스 라이브러리는 트랜스포머 모델과 토크나이저를 불러와 간단하게 모델 학습과 추론을 수행할 수 있다. 모델은 바디(body)와 헤드(head)로 구분되며, 같은 바디를 사용해 다른 작업을 수행할 수 있도록 설계되었다.

### 3.3.1 모델 불러오기
AutoModel과 AutoTokenizer 클래스를 사용해 BERT나 GPT-2 같은 모델을 불러올 수 있다. 예를 들어 BERT 모델과 GPT-2 모델을 거의 동일한 코드로 불러와 텍스트 토큰화를 수행한 뒤 모델에 입력할 수 있다.

### 3.3.2 토크나이저 사용하기
토크나이저는 텍스트를 토큰 단위로 나누고, 각 토큰을 아이디로 변환하는 역할을 한다. AutoTokenizer 클래스를 통해 쉽게 토크나이저를 불러와 사용할 수 있으며, 여러 문장을 한 번에 처리하거나, 패딩을 추가하여 길이를 맞출 수도 있다.

## 3.4 모델 학습하기
허깅페이스 트랜스포머는 Trainer API를 제공하여 모델 학습 과정을 간단하게 처리할 수 있다. Trainer API는 학습에 필요한 다양한 기능을 제공하여 학습을 자동화하고, 필요한 학습 인자와 평가 함수만 정의하면 된다. 또한, 트레이너 API를 사용하지 않고 직접 모델을 학습시키는 방법도 제공한다.

## 3.5 모델 추론하기
학습이 완료된 모델을 사용하여 새로운 데이터에 대한 추론을 수행할 수 있다. 학습된 모델은 텍스트 분류, 감정 분석 등 다양한 작업에 활용되며, 허깅페이스 허브에 업로드하여 공유할 수 있다.


# 4. 말 잘 듣는 모델 만들기

## 4.1 코딩 테스트 통과하기: 사전 학습과 지도 미세 조정

대규모 언어 모델(LLM)은 대량의 텍스트 데이터를 학습해 뛰어난 텍스트 생성 능력을 보여주었다. 하지만, 기본적으로 LLM은 사용자의 요청에 맞춰 답변하는 것이 아니라, 다음에 올 단어를 예측하는 방식으로 학습된 모델이기 때문에 한계가 있다. 이를 해결하기 위해 LLM은 **사전 학습**과 **지도 미세 조정(Supervised Fine-Tuning)** 단계를 거친다.

### 4.1.1 사전 학습
LLM의 사전 학습은 기본적인 프로그래밍 개념을 학습하는 과정과 유사하다. LLM은 파이썬 문법, 변수 선언, 반복문, 조건문과 같은 기초적인 개념을 학습하고, 대규모 텍스트 데이터를 통해 다음 단어를 예측하는 언어 모델링을 학습한다. 이 과정에서 LLM은 언어의 구조를 이해하고, 다양한 문장에서 다음에 올 단어를 예측하는 능력을 갖추게 된다.

사전 학습은 LLM이 언어에 대한 전반적인 이해도를 높이는 과정으로, 대규모 텍스트 데이터(예: 웹 페이지, 블로그, 코드 데이터 등)를 사용하여 이루어진다. 사전 학습을 통해 LLM은 다양한 언어적 상황에서 적절한 단어를 예측할 수 있는 능력을 가지게 된다.

### 4.1.2 지도 미세 조정
사전 학습을 거친 LLM은 지도 미세 조정 과정을 통해 특정 작업에 맞게 조정된다. **지도 미세 조정**은 사용자의 지시와 그에 따른 응답으로 이루어진 데이터셋을 기반으로 모델을 학습시키는 과정이다. 예를 들어, 사용자가 코딩 테스트에서 문제를 풀기 위해 작성한 코드와 그에 대한 피드백 데이터를 학습하게 된다. 이를 통해 LLM은 특정 요구에 맞는 정제된 응답을 제공할 수 있도록 조정된다.

이 과정에서 사용되는 데이터는 **지시 데이터셋(instruction dataset)**이라고 하며, 이는 사용자의 요청과 그에 대한 적절한 응답으로 구성된다. OpenAI는 챗GPT를 개발하면서 13,000개 이상의 지시 데이터셋을 수집해 모델을 학습시켰다.

## 4.2 채점 모델로 코드 가독성 높이기

코드 가독성은 개발자들이 코드 리뷰와 협업을 할 때 중요한 요소이다. 이를 위해 **코드 가독성 채점 모델**이 사용되며, 이 모델은 LLM을 기반으로 학습된다. 채점 모델은 두 가지 코드 중 어느 코드가 더 가독성이 높은지를 선택하는 **선호 학습(preference learning)** 방식을 사용한다. 

### 4.2.1 선호 학습을 위한 데이터셋 구축
채점 모델을 학습시키기 위해서는 사람이 더 선호하는 코드와 그렇지 않은 코드를 비교한 데이터를 수집한다. 이러한 데이터를 **선호 데이터셋(preference dataset)**이라고 하며, 더 가독성이 높은 코드를 **선호 데이터(chosen data)**로, 그렇지 않은 코드를 **비선호 데이터(rejected data)**로 분류한다. LLM은 이 데이터를 학습하여 가독성이 높은 코드를 선택하는 능력을 갖추게 된다.

이 과정에서 중요한 것은, 가독성 점수를 평가하기보다는 두 코드를 비교하여 더 가독성이 높은 코드를 선택하는 방식으로 데이터를 수집하는 것이 효과적이라는 점이다. 이 방식은 **지도 미세 조정(Supervised Fine-Tuning)** 방식으로 학습된다.

## 4.3 강화 학습이 꼭 필요할까?

OpenAI는 챗GPT를 학습시키기 위해 **강화 학습(Reinforcement Learning from Human Feedback, RLHF)**을 사용했다. RLHF는 LLM이 사람의 선호도를 반영하여 더 나은 답변을 생성할 수 있도록 학습하는 방법이다. 그러나 강화 학습은 하이퍼파라미터에 민감하고 학습이 불안정해 많은 연구자들이 어려움을 겪어 왔다. 이를 해결하기 위해 강화 학습을 사용하지 않고 선호를 학습하는 여러 방법들이 개발되었다.

### 4.3.1 기각 샘플링 (Rejection Sampling)
기각 샘플링은 리워드 모델을 통해 가장 높은 점수를 받은 응답만을 선택하여 학습하는 방식이다. 이는 간단하고 직관적인 방법으로, 리워드 모델로 평가한 결과 중 점수가 가장 높은 응답만을 지도 미세 조정에 사용한다. 이를 통해 안정적이고 효율적으로 사람의 선호도를 반영한 학습이 가능하다.

### 4.3.2 직접 선호 최적화 (Direct Preference Optimization, DPO)
DPO는 리워드 모델 없이 선호 데이터셋을 직접 학습하는 방법이다. 기존의 RLHF와 달리, DPO는 리워드 모델을 만들지 않고 바로 선호 데이터를 기반으로 LLM을 학습시킨다. 이 방식은 학습 과정이 단순하며, 선호 학습의 성능을 빠르게 높일 수 있다. DPO는 2024년 기준으로 가장 많이 사용되는 선호 학습 방법이다.


# 5. GPU 효율적인 학습

## 5.1 GPU에 올라가는 데이터 살펴보기
딥러닝 모델은 많은 행렬 곱셈을 통해 학습과 추론을 수행하며, 이 과정에서 GPU가 효율적으로 활용된다. 그러나 LLM의 크기가 커짐에 따라 하나의 GPU에 모델을 모두 올리기 어려운 경우가 많아졌다. 이 장에서는 GPU의 한정된 메모리를 효율적으로 사용하는 방법을 설명한다.

### 5.1.1 딥러닝 모델의 데이터 타입
딥러닝 모델은 보통 32비트 부동소수점(float32)을 사용하지만, 모델의 크기가 커지면서 16비트 부동소수점(fp16)과 bfloat16 형식으로 변환해 메모리 사용을 줄이는 양자화 기술이 개발되었다. 이 기술을 통해 더 적은 메모리로도 LLM을 학습하고 추론할 수 있다.

### 5.1.2 양자화로 모델 용량 줄이기
양자화는 모델의 파라미터를 적은 비트의 형식으로 변환해 메모리 사용을 줄이는 방법이다. fp32 형식을 fp16이나 int8로 변환하면 모델의 용량을 크게 줄일 수 있지만, 정보 손실이 발생할 수 있어 이를 최소화하는 것이 중요하다.

## 5.2 단일 GPU 효율적으로 활용하기
GPU의 메모리는 제한적이므로, 이를 효율적으로 활용하기 위한 두 가지 주요 기법이 소개된다.
> 그레이디언트 누적과 그레이디언트 체크포인팅.

### 5.2.1 그레이디언트 누적
그레이디언트 누적은 배치 크기를 제한적으로 설정하여 메모리 부족 문제를 해결하는 방법이다. 여러 배치의 학습 결과를 누적한 후 모델을 업데이트하여 마치 더 큰 배치를 사용하는 것과 같은 효과를 낸다.

### 5.2.2 그레이디언트 체크포인팅
그레이디언트 체크포인팅은 순전파 과정에서 모든 데이터를 저장하지 않고, 일부만 저장하여 메모리 사용을 줄이는 방법이다. 메모리 효율성은 높아지지만, 계산 시간이 증가할 수 있다.

## 5.3 분산 학습과 ZeRO
분산 학습은 여러 GPU를 사용해 모델 학습을 가속화하거나 큰 모델을 학습하는 방법이다.

### 5.3.1 데이터 병렬화와 모델 병렬화
데이터 병렬화는 동일한 모델을 여러 GPU에 올려 학습 데이터를 병렬로 처리하는 방법이며, 모델 병렬화는 모델을 여러 GPU에 나누어 학습하는 방법이다. 각각의 방법은 모델 크기와 학습 속도 요구에 따라 선택된다.

### 5.3.2 ZeRO(Zero Redundancy Optimizer)
ZeRO는 중복되는 메모리 사용을 줄이기 위한 방법으로, 모델 파라미터, 그레이디언트, 옵티마이저 상태를 여러 GPU에 나눠 저장해 메모리 사용을 최소화한다. 이를 통해 대규모 모델도 효율적으로 학습할 수 있다.

## 5.4 효율적인 학습 방법(PEFT): LoRA
LoRA(Low-Rank Adaptation)는 LLM의 일부 파라미터만 학습하여 메모리 사용을 줄이는 PEFT(Param Efficient Fine-Tuning) 방법이다.

### 5.4.1 LoRA의 원리
LoRA는 파라미터 행렬을 두 개의 더 작은 행렬로 분해하여 학습함으로써, 전체 파라미터 대신 일부 파라미터만 학습하는 방법이다. 이를 통해 학습에 필요한 메모리와 연산량을 줄일 수 있다.

## 5.5 효율적인 학습 방법(PEFT): QLoRA
QLoRA는 LoRA에 양자화를 추가하여 더 적은 메모리로 모델을 학습하는 방법이다. 16비트 대신 4비트로 모델을 저장하고, 양자화 상수에 대한 2차 양자화도 적용한다. 페이지 옵티마이저 기능을 사용해 OOM(Out of Memory) 에러를 방지한다.


# 6. sLLM 학습하기

## 6.1 Text2SQL 데이터셋

### 6.1.1 대표적인 Text2SQL 데이터셋
이번 장에서는 범용 LLM에 비해 비용 효율적이며 특정 작업에 특화된 **sLLM(Specialized Large Language Model)**에 대해 다룬다. **Text2SQL**은 자연어로 작성된 요청을 SQL로 변환하는 작업을 말한다. 대표적인 데이터셋으로 **WikiSQL**과 **Spider**가 있으며, 이 두 데이터셋은 주로 영어로 구성되어 있다. WikiSQL은 단순한 SQL 쿼리로 구성된 반면, Spider는 더 복잡한 SQL 쿼리를 포함한다.

한국어 데이터셋으로는 **AI 허브**에서 제공하는 NL2SQL 데이터가 있지만, 현재 공개가 중단된 상태이다. -> 실습에서는 합성 데이터셋을 사용.

## 6.2 성능 평가 파이프라인 준비하기

### 6.2.1 Text2SQL 평가 방식
기존의 평가 방식으로는 **EM(Exact Match)** 방식과 **실행 정확도(Execution Accuracy)** 방식이 있지만, 이번 실습에서는 **GPT-4**를 활용하여 평가를 수행한다. 평가 데이터셋은 8개의 데이터베이스로 구성되며, 게임 도메인(db_id = 1)을 평가용 데이터셋으로 사용힌다.

### 6.2.2 SQL 생성 프롬프트
SQL 생성을 위한 프롬프트는 `make_prompt` 함수를 사용하여 생성되며, DDL과 자연어 질문을 기반으로 SQL 쿼리를 생성하는 명령을 포함한다. 학습 데이터는 정답 SQL을 포함하고, 생성 시에는 SQL 부분을 빈 문자열로 남겨두어 학습과 추론을 구분한다.

## 6.3 실습: 미세 조정 수행하기

### 6.3.1 기초 모델 평가하기
실습에서는 한국어 사전 학습 모델인 **beomi/Yi-Ko-6B**를 사용한다. `make_inference_pipeline` 함수를 통해 기초 모델을 불러와 SQL 쿼리를 생성하고, 그 결과를 평가한다. 기초 모델은 기본적인 SQL 생성 능력이 있지만 추가적인 학습이 필요하다.

### 6.3.2 미세 조정 수행
미세 조정에는 **autotrain-advanced** 라이브러리를 사용하며, 학습 데이터를 준비한 후 `make_prompt` 함수를 이용해 프롬프트를 생성한다. 미세 조정은 LoRA 설정을 적용해 메모리 효율을 높이고, 학습을 진행한다.

### 6.3.3 성능 평가
미세 조정 후, GPT-4를 활용해 평가를 수행하고, LoRA 파라미터에 따른 성능 차이를 확인한다. **lora_r**과 **lora_alpha** 값을 조정하여 실험을 진행했으며, 성능을 비교한 결과 미세 조정 후 성능이 크게 향상되었다.

### 6.3.4 데이터 정제 및 성능 비교
GPT-4를 활용해 학습 데이터셋을 필터링하고, 필터링된 데이터를 이용한 학습 결과 성능이 개선되었다. 데이터셋 크기와 성능 간의 관계를 확인하기 위해 데이터를 20%씩 증가시키며 실험을 진행한 결과, 더 많은 데이터를 사용할수록 성능이 향상되었다.

### 6.3.5 기초 모델 변경
더 큰 모델인 **beomi/OPEN-SOLAR-KO-10.7B**를 사용하여 동일한 실험을 진행한 결과, 더 높은 성능을 달성할 수 있었다. 미세 조정 후 성능이 82.1%로, 기초 모델보다 월등히 높았다.