# LLM을 활용한 실전 AI 애플리케이션 개발

# 1부 | LLM의 기초 뼈대 세우기
# 1. LLM 지도
## 1.1 딥러닝과 언어 모델링
**LLM** : 딥러닝 기반의 언어 모델
> 사람의 언어를 컴퓨터가 이해하고 생성할 수 있도록 연구하는 자연어 처리 분야 중 자연어 생성에 속하며, 다음에 올 단어가 무엇일지 예측하면서 문장을 하나씩 만들어 가는 방식으로 작동한다.
### 1.1.1 데이터의 특징을 스스로 추출하는 딥러닝
> 딥러닝은 머신러닝과 달리 모델이 스스로 데이터의 특징을 찾고 분류하는 모든 과정을 학습한다.
### 1.1.2 임베딩: 딥러닝 모델이 데이터를 표현하는 방식
**임베딩** : 데이터의 의미와 특징을 포착해 숫자로 표현한 것 (ex: MBTI)
> 데이터 사이의 거리를 계산하고 거리를 바탕으로 관련 있는 데이터와 관련이 없는 데이터를 구분한다.
### 1.1.3 언어 모델링: 딥러닝 모델의 언어 학습법
**언어 모델링** : 모델이 입력받은 텍스트의 다음 단어를 예측해 텍스트를 생성하는 방식 <br><br>
**전이 학습** : 하나의 문제를 해결하는 과정에서 얻은 지식과 정보를 다른 문제를 풀 때 사용하는 방식
- **사전 학습** : 대량의 데이터로 모델을 학습시킨다.
- **미세 조정** : 특정한 문제를 해결하기 위한 데이터로 추가 학습을 시킨다.
> 언어 모델링은 자연어 처리 분야에서 **사전 학습**을 위한 과제로 사용된다.


## 1.2 언어 모델이 챗GPT가 되기까지
### 1.2.1 RNN에서 트랜스포머 아키텍처로
**RNN** : 입력하는 텍스트를 순차적으로 처리해서 다음 단어를 예측한다.
> 하나의 잠재 상태에 지금까지의 입력 텍스트의 맥락을 압축한다.<br>

**트랜스포머 아키텍처** : 순차적인 처리 방식이 아닌, 맥락을 모두 참조하는 **어텐션** 연산을 사용한다.
> 많은 연산량이 필요하다는 단점이 있지만 성능이 좋고 병렬 처리르 통해 학습 속도를 높일 수 있다.

### 1.2.2 GPT 시리즈로 보는 모델 크기와 성능의 관계
> 모델과 학습 데이터셋의 크기만 키워도 언어 모델의 성능이 크게 높아진다.
### 1.2.3 챗GPT의 등장
- **지도 미세 조정** : **정렬**을 위한 가장 핵심적인 학습 과정, 언어 모델링으로 사전 학습한 언어 모델을 **지시 데이터셋**으로 추가 학습하는 것
  - **정렬** : LLM이 생성하는 답변을 사용자의 요청 의도에 맞추는 것
  - **지시 데이터셋** : 사용자가 요청 또는 지시한 사항과 그에 대한 적절한 응답을 정리한 데이터셋
    
- **RLHF** : 사람의 피드백을 활용한 강화 학습
  - **선호 데이터셋** : 사용자가 더 선호하는 답변을 선택한 데이터셋
  > **선호 데이터셋**으로 LLM의 답변을 평가하는 **리워드 모델**을 만들고 LLM이 더 높은 점수를 받을 수 있도록 추가 학습하는데, 이때 강화학습을 사용한다.

## 1.3 LLM 애플리케이션의 시대가 열리다
### 1.3.1 지식 사용법을 획기적으로 바꾼 LLM
> LLM은 자연어 이해와 자연어 생성 두 분야로 나눠 접근했던 기존 방식과 달리, 언어 이해와 언어 생성 능력이 모두 뛰어나다.
### 1.3.2 sLLM: 더 작고 효율적인 모델 만들기
**sLLM** : 오픈소스 LLM에 추가 학습을 하는 경우, 모델 크기가 작으면서도 특정 도메인 데이터나 작업에서 높은 성능을 보이는 모델
### 1.3.3 더 효율적인 학습과 추론을 위한 기술
> LLM을 학습하고 추론할 때 GPU를 더 효율적으로 사용해 적은 GPU 자원으로도 LLM을 활용할 수 있도록 돕는 연구가 진행중이다.
### 1.3.4 LLM의 환각 현상을 대처하는 검색 증강 생성(RAG) 기술
- 환각 현상 : LLM이 잘못된 정보나 실제로 존재하지 않는 정보를 만들어 내는 현상
- **검색 증강 생성** : 프롬프트에 LLM이 답변할 대 필요한 정보를 미리 추가함으로써 잘못된 정보를 생성하는 문제를 줄이는 기술

## 1.4 LLM의 미래: 인식과 행동의 확장
- 멀티 모달 : 다양한 형식의 데이터를 입력/출력할 수 있는 모델
- 에이전트 : 텍스트 생성 능력을 이용해 계획을 세우거나 의사결정을 내리고 필요한 행동을 수행하는 기술
- 새로운 아키텍처 : 트랜스포머 아키텍처를 새로운 아키텍처로 변경해 입력을 효율적으로 처리하려는 연구

# 2. LLM의 중추, 트랜스포머 아키텍처 살펴보기
> **LLM**은 모델 크기가 큰 딥러닝 기반의 언어 모델로, 대부분의 LLM이 **트랜스포머 아키텍처**를 기반으로 한다.
## 2.1 트랜스포머 아키텍처란
- **RNN** : 텍스트를 순차적으로 하나씩 입력하는 형태 <br>
- **트랜스포머 아키텍처**
  > 언어를 이해하는 **인코더**와 언어를 생성하는 **디코더**로 나뉜다.
  - 셀프 어텐션 : 입력된 문장 내의 각 단어가 서로 어떤 관련이 있는지 계산해서 각 단어의 표현을 조정한다.
  - 구성 요소 : **임베딩, 위치 인코딩, 층 정규화, 멀티 헤드 어텐션, 피드 포워드**
    
## 2.2 텍스트를 임베딩으로 변환하기
### 2.2.1 토큰화
- **토큰화** : 텍스트를 적절한 단위로 나누고 숫자 아이디를 부여하는 것
- 어떤 토큰이 어떤 숫자 아이디로 연결됐는지 기록해 둔 사전을 만든다.
### 2.2.2 토큰 임베딩으로 변환하기
> 임베딩 시, 토큰을 임의의 숫자 집합으로 바꾸는데 임베딩 층이 단어의 의미를 담기 위해서는 딥러닝 모델이 학습 데이터로 훈련을 해야한다.
### 2.2.3 위치 인코딩
> 트랜스포머는 RNN과 달리 입력을 동시에 처리하므로 순서 정보를 추가해주어야 한다.
- 위치 인코딩 : 위치에 따른 임베딩 층을 추가해 학습 데이터를 통해 학습한다.
  - **절대적 위치 인코딩** : 입력 토큰의 위치에 다라 고정된 임베딩을 더해준다.
  - **상대적 위치 인코딩**

## 2.3 어텐션 이해하기
### 2.3.1 사람이 글을 읽는 방법과 어텐션
**어텐션** : 사람이 **단어 사이의 관계**를 고민하는 과정을 딥러닝 모델이 수행할 수 있도록 모방한 연산
### 2.3.2 쿼리, 키, 값 이해하기
- **쿼리** : 입력하는 검색어
- **키** : 쿼리와 관련이 있는지 계산하기 위해 문서가 가진 특징
- **값** : 쿼리와 관련이 깊은 키를 가진 문서
> 입력 데이터 사이의 관련도는 규칙이 아니라 데이터 자체에서 계산해야 한다.
> 가중치를 통해 토큰과 토큰 사이의 관계를 계산하는 능력을 학습시킨다. 쿼리, 키, 값을 가중치를 통해 내부적으로 토큰 사이의 관계를 계산해서 주변 맥락을 반영하는 방법을 학습한다.
### 2.3.3 코드로 보는 어텐션
### 2.3.4 멀티 헤드 어텐션
- 멀티 헤드 어텐션 : 여러 어텐션 연산을 동시에 적용해 성능을 높인 것

## 2.4 정규화와 피드 포워드 층
- 정규화 : 딥러닝 모델에서 **입력이 일정한 분포를 갖도록** 만들어 학습이 안정적이고 빨라질 수 있도록 하는 기법
### 2.4.1 층 정규화 이해하기
- 배치 정규화 : 모델에 입력으로 들어가는 미니 배치 사이에 정규화를 수행한다. 주로 이미지 처리에 사용한다.
- 층 정규화 : 각 토큰 임베딩의 평균과 표준편차를 구해 정규화를 수행한다. 주로 자연어 처리에 사용한다.
  > **배치 정규화**의 경우 정규화에 포함되는 데이터의 수가 제각각이라 정규화 효과를 보장하기 어렵다. **층 정규화**는 데이터의 수가 다르더라도 각 토큰 임베딩별로 정규화를 수행하기 때문에 정규화 효과에 차이가 없다. 
### 2.4.2 피드 포워드 층
- 피드 포워드 층 : 데이터의 특징들을 학습하는 **완전 연결 층**, 입력 텍스트 전체를 이해하는 역할을 담당한다.
  
## 2.5 인코더
> 멀티 헤드 어텐션, 층 정규화, 피드 포워드 층이 반복되는 형태이다. **잔차 연결**이 존재하는데, 이는 안정적인 학습이 가능하도록 입력을 다시 더해주는 형태로 구현한다. 인코더 블록을 반복해서 쌓아 만든다.

## 2.6 디코더
- 인코더와 달리 **마스크 멀티 헤드 어텐션**을 사용한다.
  > 디코더는 앞에서 생성한 토큰을 기반으로 다음 토큰을 생성한다. (= 인과적, 자기 회귀적) 따라서 특정 시점에는 그 이전에 생성된 토큰까지만 확인할 수 있도록 **마스크**를 추가한다.
- 인코더와 달리 **크로스 어텐션**이 있다.
  > 크로스 어텐션 : 인코더의 결과를 디코더가 활용하는 것
- 디코더 층을 여러번 쌓아 만든다.
  
## 2.7 BERT, GPT, T5 등 트랜스포머를 활용한 아키텍처
### 2.7.1 인코더를 활용한 BERT
> 양방향 문맥을 이해할 수 있어 자연어 이해 작업에서 뛰어난 성능을 보인다.
### 2.7.2 디코더를 활용한 GPT
> 단방향 방식이며, 다음 토큰을 예측하는 방식으로 사전 학습을 수행한다.
### 2.7.3 인코더와 디코더를 모두 사용하는 BART, T5

## 2.8 주요 사전 학습 메커니즘
> 디코더 모델을 학습시키는 **인과적 언어 모델링**과 인코더 모델을 학습시키는 **마스크 언어 모델링**이 있다.
### 2.8.1 인과적 언어 모델링
- 문장의 시작부터 끝까지 **순차적으로** 단어를 예측하는 방식이다.
### 2.8.2 마스크 언어 모델링
- 입력 단어의 일부를 마스크 처리하고 그 단어를 맞추는 작업으로 모델을 학습시킨다.

# 3. 트랜스포머 모델을 다루기 위한 허깅페이스 트랜스포머 라이브러리
## 3.1 허깅페이스 트랜스포머란
**허깅페이스 트랜스포머** : 다양한 트랜스포머 모델을 **통일된 인터페이스**로 사용할 수 있도록 지원하는 오픈소스 라이브러리
- transformers 라이브러리 : 트렌스포머 모델과 토크나이저를 활용할 때 사용
- datasets 라이브러리 : 데이터셋을 공개하고 쉽게 가져다 쓸 수 있도록 지원

## 3.2 허깅페이스 허브 탐색하기
- 허브 : 다양한 사전 학습 모델과 데이터셋을 탐색하고 쉽게 불러와 사용할 수 있도록 제공하는 온라인 플랫폼
### 3.2.1 모델 허브
> 모델이 어떤 작업에 사용하는지, 어떤 언어로 학습된 모델인지 등 다양한 기준으로 분류되어 있다.
### 3.2.2 데이터셋 허브
> 모델 허브와 달리 분류 기준에 데이터셋 크기, 데이터 유형 등이 추가로 있다.
- KLUE : 한국어 언어 이해 평가의 약자로 텍스트 분류, 기계 독해, 문장 유사도 판단 등 다양한 작업에서 모델의 성능을 평가하기 위해 개발된 벤치마크 데이터셋
### 3.2.3 모델 데모를 공개하고 사용할 수 있는 스페이스
- 스페이스 : 사용자가 자신의 모델 데모를 간편하게 공개할 수 있는 기능, 별도의 복잡한 웹 페이지 개발 없이 모델 데모를 공유할 수 있다.
> 허깅페이스는 다양한 오픈소스 LLM과 그 성능 정보를 게시하는 리더보드를 운영한다.

## 3.3 허깅페이스 라이브러리 사용법 익히기
> 모델을 학습시키거나 추론하기 위해서는 모델, 토크나이저, 데이터셋이 필요하다.
### 3.3.1 모델 활용하기
> 허깅페이스에서는 모델을 **바디와 헤드**로 구분한다. 이는 같은 바디를 사용하면서 다른 작업에 사용할 수 있도록 만들기 위함이다.
- AutoModel : 모델의 바디를 불러오는 클래스
- config.json 파일 : 허깅페이스 모델을 저장할 때 함께 저장되는 파일으로, 이를 참고해 적절한 모델과 토크나이저를 불러온다.
### 3.3.2 토크나이저 활용하기
- **토크나이저** : 텍스트를 토큰 단위로 나누고 각 토큰을 대응하는 토큰 아이디로 변환한다. 필요한 경우 특수 토큰을 추가하는 역할도 한다.
- AutoTokenizer : 토크나이저를 불러오는 클래스
- tokenizer_config.json : 토크나이저의 종류나 설정에 대한 정보를 갖고 있다.
- tokenizer.json : 실제 어휘 사전 정보를 갖고 있다.

- input_ids : 토큰 아이디의 리스트
- attention_mask : 토큰이 실제 텍스트인지 아니면 길이를 맞추기 위해 추가한 패딩인지 알려준다.
  > 패딩은 모델에 입력하는 토큰 아이디의 길이를 맞추기 위해 추가하는 특수 토큰이다.
- token_type_ids : 토큰이 속한 문장의 아이디를 알려준다.
  > 문장을 구분하는 역할을 한다. 
### 3.3.3 데이터셋 활용하기
1. 데이터셋 저장소에 있는 데이터를 불러온다. (load_dataset 함수)
2. 로컬 파일이나 파이썬 객체를 데이터셋으로 사용한다.

## 3.4 모델 학습시키기
> 모델을 학습 시키기 위해서는 사용할 데이터셋을 준비하고, 모델과 토크나이저를 불러온다.
### 3.4.1 데이터 준비
- 데이터셋을 불러와 변수에 저장한다.
- remove_columns 메서드 : 데이터셋에서 지정한 컬럼을 삭제한다.
- train_test_split 메서드 : 입력한 test_size 값에 맞춰 학습 데이터셋과 테스트 데이터셋으로 분리한다.
### 3.4.2 트레이너 API를 사용해 학습하기
- **트레이너 API** : 허깅페이스에서 제공하는 기능으로, 간편하게 모델 학습을 수행할 수 있도록 학습 과정을 추상화한 것이다. 학습에 필요한 다양한 기능을 학습 인자만으로 쉽게 활용할 수 있다.
- TrainingArguments : 학습 인자를 입력한다. (학습 에포크 수, 배치 크기, 결과를 저장할 폴더, 평가를 수행할 빈도 등)
- compute_metrics : 학습이 잘 이뤄지고 있는지 확인할 때 사용할 평가 지표를 정의한다.
- Trainer : 준비한 데이터셋과 설정을 인자로 전달하고 train() 메서드로 학습을 진행한다.
- evaluate() : 테스트 데이터셋에 대한 성능 평가를 수행한다.

- 트레이너 API의 장점 : 추상화를 통해 간편하게 사용할 수 있다.
- 트레이너 API의 단점 : 내부 동작을 파악하기 어렵다.
### 3.4.3 트레이너 API를 사용하지 않고 학습하기
- 트레이너가 내부적으로 수행하던 GPU로의 모델 이동을 직접 수행해야 한다.
- 데이터 전처리 과정 : tokenize_function (토큰화) -> rename_column -> remove_column -> DataLoader (데이터셋을 배치 데이터로)
- 학습 : train() (학습 모드 변경) -> 배치 데이터를 모델에 입력으로 전달 -> 모델 계산 -> 손실 값으로 역전파 -> step() (모델 업데이트)
- 평가 : 추론 모드 -> 모델 계산 결과로 예측 정보 찾기 -> 실제와 비교해 정확도 계산

- 트레이너를 사용하지 않는 장점 : 내부 동작을 명확히 확인할 수 있고 학습 과정을 조절할 수 있다.
### 3.4.4 학습한 모델 업로드하기
> push_to_hub() 메서드로 업로드 한다.

## 3.5 모델 추론하기
### 3.5.1 파이프라인을 활용한 추론
**pipeline** : 허깅페이스는 토크나이저와 모델을 결합해 데이터의 전후처리와 모델 추론을 간단하게 수행하는 기능을 제공한다.
> 작업 종류, 모델, 설정을 입력으로 받는다.
### 3.5.2 직접 추론하기
1. 토큰화 수행 (tokenizer)
2. 모델 추론 수행
3. 가장 큰 예측 확률을 갖는 클래스 추출

# 4. 말 잘 듣는 모델 만들기
단순히 다음 단어를 예측하는 방식으로 학습한 LLM은 사용자의 요청에 적절히 응답하기보다는 사용자의 말에 이어질 법한 텍스트를 생성한다는 한계가 존재한다.
> 그렇다면 어떻게 말 잘 듣는 모델을 만드는 것이 가능해졌을까?
1. 요청과 답변 형식으로 된 지시 데이터셋으로 학습시킨다.
2. 사용자의 선호를 학습시킨다.
  - 강화 학습을 사용하는 방법
  - 강화 학습을 사용하지 않는 방법
## 4.1 코딩 테스트 통과하기 : 사전 학습과 지도 미세 조정
> LLM이 사용자의 요청에 응답할 수 있도록 학습하는 방법은 코딩테스트를 통과하기 위한 사람의 공부 과정과 유사하다.
### 4.1.1 코딩 개념 익히기: LLM의 사전 학습
> LLM의 사전 학습은 다양한 자료를 보며 프로그래밍을 처음 공부하는 과정과 유사하다.

- LLM은 보통 인터넷상에 있는 다양한 텍스트 데이터를 수집한 대용량의 텍스트로 사전 학습한다.
- LLM은 딥러닝 기반의 언어 보델으로, 다음 단어를 예측하는 언어 모델링을 통해 학습한다.
- 사전 학습 동안은 LLM이 언어에 대한 전체적인 이해도가 높아진다.
- 학습 시, 학습 데이터의 일부를 입력으로 넣고 바로 다음에 나오는 정답 토큰을 맞추도록 학습한다.
### 4.1.2 연습문제 풀어보기: 지도 미세 조정
> LLM이 **사용자의 요청에 적절히 응답하기 위한 과정**은 코딩테스트를 위해 연습 문제를 풀어보는 과정과 유사하다.

- **지도 미세 조정** : 요청의 형식을 적절히 해석하고, 응답의 형태를 적절히 작성하며, 요청과 응답이 잘 연결되도록 추가로 학습하는 것
- 지도란, 학습 데이터에 정답이 포함되어 있다는 의미이다.
- **정렬** : 지도 미세 조정을 통해 사용자의 요청에 맞춰 응답하도록 학습하는 것
- **지시 데이터 셋** : 지도 미세 조정에 사용하는 데이터 셋, 사용자의 요청을 형식에 맞춰 작성하고 그에 대해 적절한 형식의 응답을 하는 형태

> **지도 미세 조정**에서 사전학습 때와 동일하게 다음 단어를 예측하는 **인과적 언어 모델링**을 사용해 학습하지만, 학습하는 데이터셋에 차이가 있다. 
### 4.1.3 좋은 지시 데이터셋이 갖춰야 할 조건
1. 지시 데이터셋을 작은 규모로 구축하더라도 모델이 지시사항의 형식을 인식하고 답변하도록 만들 수 있다.
2. 지시사항이 다양한 형태이고 답변의 품질이 높을수록 모델의 답변 품질도 높아진다.
3. 학습 데이터의 품질을 높이기 위해 모델의 목적에 맞춰 학습 데이터의 교육적 가치를 판단하고 교육적 가치가 낮은 데이터를 필터링하는 방법을 사용할 수 있다.
4. 교재의 예제 데이터와 같은 고품질의 데이터를 학습 데이터에 추가하면 성능을 크게 높일 수 있다.
## 4.2 채점 모델로 코드 가독성 높이기
> LLM이 사람이 선호하는 방식으로 답변할 수 있도록 조정하는 방식은 엔지니어가 코드의 가독성을 높이는 방식과 유사하다.
### 4.2.1 선호 데이터셋을 사용한 채점 모델 만들기
- **선호 데이터셋** : 두 데이터 중 사람이 더 선호하는 데이터를 선택한 데이터셋
- 리워드 모델 : 생성된 답변의 점수를 평가하는 모델
  > 지도 미세 조정을 마친 LLM은 사용자의 요청에 맞춰 응답하기 때문에 사용자에게 결과적으로 해가 될 수 있는 정보를 제공하는 등의 문제가 발생하는데, 이를 줄이기 위한 방법이다.
  > 지도 미세 조정을 마친 LLM에 지시사항을 입력해 여러 응답을 생성하고, 레이블러가 더 좋다고 판단하는 순서로 선호 데이터셋을 구축한다.
### 4.2.2 강화 학습: 높은 코드 가독성 점수를 향해
> 리워드 모델로부터 더 높은 점수를 받도록 학습시킨 과정은 엔지니어가 코드 가독성 채점 모델에서 더 나은 점수를 받기 위해 노력하는 과정과 유사하다.

- **RLHF** : 사람의 피드백을 활용한 강화 학습
- 에이전트가 환경에서 행동을 한다.
- 행동에 따라 환경의 상태가 바뀌고 행동에 대한 보상이 생기는데, 에이전트는 변화된 상태를 인식하고 보상을 받는다.
- 에이전트는 더 많은 보상을 받도록 행동을 수정하며 학습한다.
- 에피소드 : 에이전트가 연속적으로 수행하는 행동의 모음
### 4.2.3 PPO: 보상 해킹 피하기
- **보상 해킹** : 평가 모델의 높은 점수를 받는 과정에서 다른 능력이 감소하거나 평가 점수만 높게 받을 수 있는 우회로를 찾는 현상
  > 보상 해킹을 피하기 위한 방법으로 **PPO**라는 강화 학습 방법을 사용한다.
- **PPO** : **근접 정책 최적화**라는 학습 방법으로, 지도 미세 조정 모델을 기준으로 학습하는 모델이 너무 멀지 않게 가까운 범위에서 리워드 모델의 높은 점수를 찾도록 한다는 의미
### 4.2.4 RLHF: 멋지지만 피할 수 있다면...
- RLHF의 단점
  1. 리워드 모델의 성능에 따라 제대로 학습되지 않는 경우가 있다.
  2. 리소스가 많이 필요하다.
  3. 하이퍼파라미터에 민감하고 학습이 불안정하다.
## 4.3 강화 학습이 꼭 필요할까?
### 4.3.1 기각 샘플링: 단순히 가장 점수가 높은 데이터를 사용한다면?
- **기각 샘플링** : 여러 생성 결과 중 리워드 모델이 가장 높은 점수를 준 결과를 LLM의 지도 미세 조정에 사용하는 방법
- 강화 학습을 사용하지 않아 학습이 안정적이고 간단하고 직관적인데다가 효과도 좋다.
- 기각 샘플링은 그 자체로도 사람의 선호를 학습하는 데 효과적이나, 강화 학습 전에 활용함으로써 학습을 더 안정적을 만들 수 있다.
### 4.3.2 DPO: 선호 데이터셋을 직접 학습하기
- **DPO(직접 선호 최적화)** : 리워드 모델과 강화 학습을 사용하지 않고 선호 데이터셋을 직접 LLM이 학습하는 방식으로 변경한 방법
  > 리워드 모델을 만들고 관리하고, 강화 학습으로 사람의 선호를 반영하는 것은 쉽지 않다.
  - RLHF에 비해 단순하며 효과적이다.
### 4.3.3 DPO를 사용해 학습한 모델들
> 선호 데이터셋을 구축하기 위해서는 많은 시간과 노력이 필요하다. 따라서 선호 데이터셋을 효율적으로 구축하는 것이 중요하다.
1. 제퍼-7B-베타 : AI를 사용해 선호 데이터셋 구축
2. 뉴럴-챗-7B : 성능이 뛰어난 모델의 생성 결과를 선호 데이터, 성능이 낮은 모델의 생성 결과를 비선호 데이터로 사용
3. 튈루-2 : 파라미터카 큰 모델에 대해 DPO의 확장성 의문 해결

# 2부 | LLM 길들이기
# 5. GPU 효율적인 학습
- **GPU** : 단순한 곱셈을 동시에 여러 개 처리하는 데 특화된 처리 장치
  - 딥러닝 모델의 연산을 빠르게 처리하기 위해 활용된다.
  - 가격이 비싸다.
## 5.1 GPU에 올라가는 데이터 살펴보기
- OOM 에러 : 한정된 GPU 메모리에 데이터가 가득 차 더 이상 새로운 데이터를 추가하지 못해 발생하는 에러
   > 딥러닝 모델을 학습시키고 추론하기 위해 GPU를 사용할 때 자주 만나는 에러이다.
### 5.1.1 딥러닝 모델의 데이터 타입
> 딥러닝 모델은 수많은 행렬 곱셈을 위한 파라미터의 집합이다.
> 모델의 용량이 커지며, 성능을 유지하며 적은 비트의 데이터 타입을 사용하는 방향으로 발전하고 있다.

- 데이터 형식으로는 bf16, fp32, fp16 등이 있다.
   - 지수 : 수를 표현할 수 있는 범위의 크기를 결정
   - 가수 : 표현할 수 있는 수의 촘촘함을 결정
- 딥러닝 모델의 용량 : 파라미터 수 X 파라미터 당 비트(바이트)
### 5.1.2 양자화로 모델 용량 줄이기
- **양자화** : 더 적은 비트로 모델을 표현하는 기술
> 양자화를 수행하면 그 전의 수가 담고 있던 정보가 소실될 수 있어 딥러닝 모델의 성능이 저하된다.
> 원본 데이터의 정보를 소실 없이 유지하려면? 데이터 형식의 수를 최대한 낭비하지 않고 사용해야 한다.

1. 두 데이터 형식의 최댓값과 최솟값을 각각 대응시키는 양자화 방식
  > 양쪽 끝 수가 낭비되는 문제 발생
2. 존재하는 데이터의 최댓값 범위로 양자화하는 방식
  > 이상치가 존재하는 경우 취약
3. **데이터를 묶은 블록 단위로 양자화 수행**
4. **퀀타일 방식** : 입력 데이터를 크기순으로 등수를 매겨 대응되도록 배치하는 방식
  > 계산량이 많고 별도의 메모리를 사용한다는 단점 존재
### 5.1.3 GPU 메모리 분해하기
> GPU 메모리에 저장되는 데이터 : 모델 파라미터, 그레디언트, 옵티마이저 상태, 순전파 상태
> 딥러닝 학습 과정 : 순전파 수행 -> 역전파 수행 (그레디언트 생성) -> 옵티마이저로 모델 업데이트
  (+) 순전파 : 신경망에서 입력층에서 출력층으로 신호가 전달되는 과정
      역전파 : 신경망의 가중치를 조정하여 학습하는 과정

- torch.cuda.memory_allocated() : 파이토치의 메모리 확인 함수
- 모델의 메모리 사용량 확인
  - form_pretrained() : 모델과 토크나이저 내려받기
- 그레디언트와 옵티마이저 상태의 메모리 사용량 확인
- GPU 메모리의 데이터 삭제하기
  - gc.collect : 사용하지 않는 메모리 회수
  - torch.cuda.empty_cache() : 더 이상 사용하지 않는 GPU 메모리 반환

> 배치 크기가 증가해도 모델, 그레디언트, 옵티마이저 상태를 저장하는 데 필요한 GPU 메모리는 동일하다. 총 메모리가 증가하는 것을 통해 **순전파 상태**의 계산에 필요한 메모리가 증가한다는 것을 알 수 있다.
    (+) 배치사이즈 : 한 번에 모델이 학습하는 데이터 샘플의 개수

## 5.2 단일 GPU 효율적으로 활용하기
> GPU의 메모리는 크기가 제한적이다. 따라서 GPU 메모리의 사용량을 줄이는 방법이 필요하다.
> 그레디언트 누적과 그레디언트 체크포인팅 모두 모델 학습 시에 **배치 크기를 키워** 모델의 학습을 더 빠르고 안정적으로 만들어준다.
  (+) 그레디언트? 기울기를 의미한다.
### 5.2.1 그레디언트 누적
- 배치 크기를 키우면 더 빠르게 수렴하고 성능이 높아지나, 순전파 상태 저장에 필요한 메모리가 증가해 OOM 에러가 발생한다.
- **그레디언트 누적** : 딥러닝 모델을 학습시킬 때 각 배치마다 모델을 업데이트하지 않고 여러 배치의 학습 데이터를 연산한 후 모델을 업데이트해 더 큰 배치 크기를 사용하는 것 같은 효과를 내는 방법이다.
- 추가적인 순전파 및 역전파 연산을 수행하므로 학습시간이 증가하는 단점이 있다.
### 5.2.2 그레디언트 체크포인팅
> 그레디언트를 계산하기 위해 순전파와 역전파를 수행하는데, 역전파 계산을 위해 순전파의 결과를 저장하고 있어야 한다.

1. 모두 저장하는 방식
  > GPU 메모리를 많이 차지한다.
2. 최소 데이터만 저장하고 나머지는 필요할 때 다시 계산하는 방식
  > 메모리를 효율적으로 사용하나, 역전파를 위해 순전파를 반복적으로 계산해야하는 단점 존재
3. **그레디언트 체크포인팅** : 순전파의 계산 결과를 모두 저장하지 않고 일부만 저장해 학습 중 GPU 메모리의 사용량을 줄이는 방법이다.
> 순전파의 전체나 마지막을 저장하는 것이 아니라, 중간중간에 값들을 저장해 메모리 사용을 줄이고 필요한 경우 체크포인트부터 다시 계산해 순전파 계산량도 줄인다.
  > 메모리 사용량은 줄지만 학습 시간이 증가한다.

## 5.3 분산 학습과 ZeRO
### 5.3.1 분산학습
- **분산 학습** : GPU를 여러 개 활용해 딥러닝 모델을 학습시키는 것
  1. 모델의 학습 속도를 높인다.
  2. 1개의 GPU로 학습이 어려운 모델을 다룬다.
- **데이터 병렬화** : 모델이 작아 하나의 GPU에 올릴 수 있는 경우 여러 GPU에 각각 모델을 올리고 학습 데이터를 병렬로 처리해 학습 속도를 높인다.
- **모델 병렬화** : 하나의 GPU에 올리기 어려운 큰 모델의 경우 모델을 여러 개의 GPU에 나눠서 올린다.
  - 파이프라인 병렬화 : 모델의 층별로 나눠 GPU에 올린다.
  - 텐서 병렬화 : 한 층의 모델도 나눠서 GPU에 올린다.
    > 행렬을 분리해도 동일한 결과를 얻을 수 있도록 행렬 곱셈을 적용한다.

> 데이터 병렬화의 경우 동일한 모델을 여러 GPU에 올리므로 메모리 낭비가 발생한다.
### 5.3.2 데이터 병렬화에서 중복 저장 줄이기(ZeRO)
- ZeRO : 하나의 모델을 하나의 GPU에 올리지 않고 모델 병렬화처럼 모델을 나눠 여러 GPU에 올리고, 각 GPU에서는 자신의 모델 부분의 연산만 수행하고 저장한다.
 > 메모리를 효율적으로 사용하면서 속도도 빠르게 유지할 수 있다.

## 5.4 효율적인 학습 방법(PEFT): LoRA
> 여러 GPU를 사용해 모델을 학습시키기는 어려우므로, 일부 파라미터만 학습하는 PEFT 방법 연구가 주목을 받고 있다.
### 5.4.1 모델 파라미터의 일부만 재구성해 학습하는 LoRA
- LoRA : 모델 파라미터를 재구성해 더 적은 파라미터를 학습함으로써 GPU 메모리 사용량을 줄인다.
- 파라미터 W(d,d)는 고정하고 행렬 A(d,r)와 행렬 B(r,d)의 곱을 학습시킨다.
  > 행렬 A와 B를 추가하는데 GPU 메모리 사용량이 줄어드는 까닭이 무엇일까?
  - 행렬 A와 B가 파라미터 W에 비해 훨씬 작다고는 하더라도 파라미터가 추가되는 것이기 때문에 모델 파라미터 용량 자체는 작게 증가한다.
  - 하지만, GPU 메모리에는 모델 파라미터뿐만 아니라, 그레디언트와 옵티마이저 상태 역시 저장된다.
  - 학습 파라미터 수가 줄면 모델 업데이트에 사용하는 옵티마이저 상태의 데이터가 줄어들어, 결과적으로 그레디언트와 옵티마이저 상태를 저장하는 메모리가 줄어든다.  
### 5.4.2 LoRA 설정 살펴보기
> LoRA를 적용할 때 결정해야 할 사항
1. 행렬 A와 B의 차원 r을 몇으로 할 지 결정한다.
  > r이 작아지면 GPU 메모리 사용량을 더 줄일 수 있으나, 모델이 학습 데이터의 패턴을 충분히 학습하지 못할 수 있다.
2. 추가한 파라미터를 기존 파라미터에 얼마나 많이 반영할지(알파)를 결정한다.
  > 알파가 커질수록 새롭게 학습한 파라미터의 중요성을 크게 고려한다.
3. 모델에 있는 파라미터 중 어떤 파라미터를 재구성할지 결정한다.
  > 보통 전체 선형 층에 적용한 경우 성능이 좋다.
### 5.4.3 코드로 LoRA 학습 사용하기
> 허깅페이스는 peft 라이브러리르 제공한다.

## 5.5 효율적인 학습 방법(PEFT): QLoRA
- QLoRA : LoRA에 양자화를 추가해 메모리 효율성을 한번 더 높인 학습 방법
  - (+) 양자화 : 기존 데이터를 더 적은 메모리를 사용하는 데이터 형식으로 변환하는 방법
- 학습 도중 OOM 에러가 발생하지 않고 안정적으로 진행할 수 있또록 페이지 옵티마이저 기능을 활용한다.
### 5.5.1 4비트 양자화와 2차 양자화
> 양자화의 핵심 과제는 기존 데이터의 정보를 최대한 유지하며 더 적은 비트를 사용하는 데이터 형식으로 변환하는 것이다.

- 기존 데이터의 분포를 알고 있다면 많은 연산이나 메모리 사용 없이도 빠르게 데이터의 순위를 정할 수 있다.
  - quantile_normal 함수
- 학습된 모델 파라미터는 거의 정규 분포에 가깝다고 알려져 있다.
- 4비트 양자화 : 입력이 정규 분포라는 가정을 활용해 모델의 성능을 거의 유지하면서 빠른 양자화를 하는 것
  > 4비트 부동소수점 데이터 형식인 NF4가 있다.
- 2차 양자화 : NF4 양자화 과정에서 생기는 32비트 상수도 효율적으로 저장하는 것
### 5.5.2 페이지 옵티마이저
> 그레디언트 체크포인팅 과정에서 일시적으로 메모리 사용량이 커지는 지점에서 발생하는 OOM 에러를 방지하기 위한 방법

- 페이지 옵티마이저 : 엔비디아의 통합 메모리를 통해 GPU가 CPU 메모리를 공유하는 것
- 통합 메모리는 CPU와 GPU가 메모리를 공유해 더 많은 GPU 메모리가 있는 것처럼 동작한다.
### 5.5.3 코드로 QLoRA 모델 활용하기
> 허깅페이스는 4비트 양자화를 위해 bitsandbytes 라이브러리를 제공한다.

# 6. sLLM 학습하기
- **sLLM** : LLM에 비해 비용 효율적이면서 특정 작업 또는 도메인에 특화되어 있다.
- SQL : 관계형 데이터베이스에서 데이터를 생성, 조회, 업데이트, 삭제하기 위해 사용하는 언어이다.
## 6.1 Text2SQL 데이터셋
### 6.1.1 대표적인 Text2SQL 데이터셋
> SQL을 생성하기 위해 필요한 데이터
  1. 어떤 데이터가 있는지 알 수 있는 데이터베이스 정보(테이블, 칼럼)
  2. 어떤 데이터를 추출하고 싶은지 나타낸 요청사항

> 대표적인 Text2SQL 데이터셋으로는 WikiSQL, Spider가 있다.
### 6.1.2 한국어 데이터셋
> 한국어 Text2SQL 데이터셋으로는 자연어 기반 질의 검색 생성 데이터가 있다.
### 6.1.3 합성 데이터 활용
> 생성한 데이터셋은 4개의 컬럼으로 구성되어 있다.
  - db_id : 테이블이 포함된 데이터베이스의 아이디
  - context : SQL 생성에 사용할 테이블 정보
  - question : 데이터 요청 사항
  - answer : 요청에 대한 SQL 정답

## 6.2 성능 평가 파이프라인 준비하기
> 뛰어난 성능의 LLM을 평가자로 활용하면 빠르게 평가를 수행하면서도 신뢰할 수 있는 평가 결과를 기대할 수 있다.
### 6.2.1 Text2SQL 평가 방식
1. EM 방식 : 생성한 SQL이 문자열 그대로 동일한지 확인한다.
  > 문자열이 동일하지 않으면 의미상으로 동일한 쿼리를 다르다고 판단할 수 있는 문제 발생
2. 실행 정확도 방식 : 쿼리를 수행할 수 있는 데이터베이스를 만들고 프로그래밍 방식으로 SQL 쿼리를 수행해 정답과 일치하는지 확인한다.
  > 쿼리를 실행할 수 있는 데이터베이스를 추가로 준비해야 한다.

> GPT를 활용한 성능 평가 파이프라인을 준비하기 위해 필요한 것
  1. 평가 데이터셋
  2. LLM이 SQL을 생성할 때 사용할 프롬프트
  3. GPT 평가에 사용할 프롬프트와 GPT-4 API 요청을 수행할 수 있는 코드
### 6.2.2 평가 데이터셋 구축
- 모델의 일반화 성능을 확인하기 위해 7개의 데이터베이스는 학습에, 1개의 데이터베이스는 평가에 사용
- GPT-4를 활용하므로 비용을 줄이며 수행하도록 100개 내외의 데이터만 사용
### 6.2.3 SQL 생성 프롬프트
- SQL 생성 명령 작성 후, 필요한 데이터 입력 후 정답에 해당하는 SQL을 마지막에 채워넣는다.
  - 학습데이터에서는 정답이 채워진 형태로 사용
  - SQL 생성 시에는 쿼리를 입력하지 않은 빈 문자열을 사용
### 6.2.4 GPT-4 평가 프롬프트와 코드 준비
- 평가를 위해 평가 데이터셋에서 요청 jsonl 파일을 생성한다.
- LLM이 생성한 SQL이 정답 SQL과 동일한 기능을 하는지 평가 후, 판단 결과를 jsonl 파일 형태로 저장한다.
- 비동기 요청 코드를 실행한다.
- 평가 결과를 csv 파일로 변환한다.

## 6.3 실습: 미세 조정 수행하기
### 6.3.1 기초 모델 평가하기
- 기초 모델로 생성하기
  - 입력한 모델로 파이프라인을 만들어 변수에 저장한다.
  - example 데이터를 입력하고 결과를 확인한다.
- 기초 모델 성능 측정
  - 평가 데이터셋을 내려받고 LLM 추론에 사용할 프롬프트를 생성한다.
  - 생성한 프롬프트를 입력해 SQL을 생성하고 변수에 저장한다.
  - 평가에 사용할 jsonl 파일을 만들고 평가 요청을 전달한다.
### 6.3.2 미세 조정 수행
> 모델의 미세 조정에는 autotrain-advanced 라이브러리를 사용한다.
- 학습 데이터를 불러온다.
  - 학습 데이터를 내려받는다.
  - 평가에 사용하기로 한 데이터를 제거한다.
  - 학습에 사용할 프롬프트를 생성하고 저장한다.
- 지도 미세 조정을 수행한다.
  > 모델 학습 과정에서 메모리 에러 발생 시, batch_size를 줄여 다시 시도한다.
- 학습을 마친 후, LoRA 어뎁터를 결합하고 허깅페이스 허브에 업로드한다.
- 미세 조정 모델로 예시 데이터에 대한 SQL을 생성해 본다.
- 학습한 모델에 대한 평가를 수행한다.
### 6.3.3 학습 데이터 정제와 미세 조정
> 정제한 데이터셋으로 미세 조정 시, 데이터셋 크기가 줄었음에도 불구하고 정제 전과 동일한 성능을 보인다.
### 6.3.4 기초 모델 변경
> 기초 모델을 더 크고 성능이 뛰어난 모델로 변경하면 높은 성능을 보인다.
### 6.3.5 모델 성능 비교
> 실습의 한계를 고려했을 때 GPT-4와 근접한 수준의 결과를 보였다.