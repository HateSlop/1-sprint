# 12. 벡터 데이터베이스로 확장하기: RAG 구현하기
## 12.1 벡터 데이터베이스란
### 12.1.1 딥러닝과 벡터 데이터베이스
> 표현 학습: 데이터가 충분하면 모델이 알아서 특징 추출

> 벡터 데이터베이스 활용 방법
- 저장: 저장할 데이터를 벡터로 변환 후 벡터 DB에 저장
- 검색: 검섹할 데이터를 벡터로 변환하고 벡터 DB에서 검색
- 결과 반환: 벡터 DB에서 검색 쿼리의 임베딩과 거리가 가까운 벡터 찾아 반환
    - 유사도 계산: 유클리드 거리, 코사인 유사도, 내적

### 12.1.2 벡터 데이터베이스 지형 파악하기
> 벡터 데이터베이스 소프트웨어 종류
- 벡터 라이브러리
- 벡터 전용 데이터베이스
- 벡터 기능 추가 데이터베이스
> 벡터 데이터베이스 기능
- 메타 데이터의 저장 및 필터링
- 데이터의 백업 및 관리
- 모니터링, 관련 AI도구 등 에코시스템과의 통합
- 데이터 보안과 엑세스 관리

## 12.2 벡터 데이터베이스 작동 원리
### 12.2.1 KNN 검색과 그 한계
> 검색하려는 벡터와 가장 가까운 K개의 이웃 벡터 찾는 방식
- 직관적, 모든 데이터 조사하여 정확
- 데이터 많으면 연산량 증가, 확장성 떨어짐.
> 과정
- 인덱스 만들기
- 검색 하기(검색 시간과 재현율이 중요)

### 12.2.2 ANN 검색이란
> 대용량 데이터셋에서 주어진 쿼리 항목과 가장 유사한 항목을 효율적으로 찾는 방법
- 임베딩 벡터 빠르게 탐색할 수 있는 구조로, 검색 시 탐색 범위 좁히는 데 집중.
- IVF, HNSW
### 12.2.3 탐색 가능한 작은 세계(NSW)
> 완전히 랜덤한 그래프와 완전히 규칙적인 그래프 사이에 적당히 랜덤하게 연결된 그래프 상태
- 완전히 규칙적인 그래프보다 탐색 단계를 줄여줌.
- 지역 최솟값에서 탐색을 종료할 문제가 생김
### 12.2.4 계층 구조
> 연결 리스트
- 새로운 데이터 추가 및 삭제가 자유로움
- 탐색 속도 느림
> 탐색 속도 높이기 위해
- 데이터 정렬
    - 스킵 리스트
        - for n to 1;
            level(n) is included in level(n-1)
        - for n to 0:
            search(level(n));
## 12.3 실습: HNSW 인덱스의 핵심 파라미터 이해하기

### 12.3.1 파라미터 m 이해하기
> m: 추가하는 임베딩 벡터에 연결하는 간선의 수
- m값이 커지면 검색 품질 개선, m값이 감소하면 검색 시간 증가
### 12.3.2 파라미터 ef_construction 이해하기
> M개의 가장 가까운 벡터를 선택할 후보군
- M증가: 성능 증가, 색인 시간 증가. 메모리 사용량, 검색 시간은 영향 안받음.
### 12.3.3 파라미터 ef_search 이해하기
> 검색 단계에서 후보군의 크기 결정

## 12.4 실습: 파인콘으로 벡터 검색 구현하기

### 12.4.1 파인콘 클라이언트 사용법
> 과정
- 인덱스 이름과 입력할 임베딩 벡터 차원수 설정해 인덱스 설정
- 생성한 인덱스의 이름을 입력해 사용할 인덱스 불러오기
- 임베딩 모델로 데이터를 임베딩으로 변환
- numpy라이브러리 데이터 타입을 리스트로 변환
- 파인콘 형식에 맞게 데이터 변환
- 데이터 검색 시 query 메서드 사용
- 데이터 수정 시 update 메서드, 데이터 삭제 시 delete 메서드 사용
- 이 과정을 CRUD(create, read, update, delete)라고 함.

## 12.5 실습: 파인콘을 활용해 멀티 모달 검색 구현하기
이미지 생성 기능을 파인콘 벡터 데이터베이스로 구현하기

### 12.5.1 데이터셋
> 데이터: 이미지 칼럼, 프롬프트 칼럼만 사용

### 12.5.2 실습 흐름
- GPT 설명 프롬프트: GPT가 생성한 이미지 설명문
- 원본 프롬프트: 이미지에 대응되는 프롬프트
- 유사 프롬프트: 원본 이미지를 이미지 임베딩으로 변환 후 검색해 찾은 프롬프트

# 13. LLM 운영하기

## 13.1 MLOps
> DevOps 개념을 머신러닝, 데이터 과학 분야로 확장한 방법론
- 데이터 수집, 전처리, 모델 학습, 평가, 배포, 모니터링 등 머신 러닝 프로젝트의 전 과정 자동화 & 효율화.
- 모델의 재현성을 보장하는 것이 매우 중요(이전에 수행된 ML 워크플로를 그대로 반복했을 때 동일한 모델을 얻을 수 있는지 여부)
- 모델 학습을 자동으로 트리거하여 새로운 데이터로 지속적으로 모델 업데이트.
- 모델 최적화

### 13.1.1 데이터 관리
> 포함시킬 데이터의 범위를 선택하고 어떤 전처리 방식을 포함시킬지, 특성 공학을 통해 어떤 특성을 추가할지에 따라 학습 데이터셋이 달라짐.
> DVC(DataVersionControl)을 통해 데이터셋 버전 관리 모델 학습 진행한 데이터셋 기록

### 13.1.2 실험 관리
> 모델 성능에 영향을 주는 다양한 하이퍼파라미터 값을 조정해 최적값 찾기.
- MLflow, W&B로 실험 관리 및 추적

### 13.1.3 모델 저장소
> 머신러닝 모델을 체계적으로 관리하고 버전 제어하는 데 필수적인 요소. 
- 모델 개발 과정에서 여러 파이프라인에서 다양한 버전의 모델이 나오는데, 이를 통합 관리
- MLflow 모델저장소, AWS 세이지메이커

### 13.1.4 모델 모니터링
> 모델이 반환하는 값의 퀄리티를 평가하는 모니터링 수행
- 모델을 배포한 후 데이터 분포가 학습 데이터와 차이가 커지면 성능 떨어짐.
- 머신러닝 시스템의 기본적인 지표 기록해 문제 여부, 추가 리소스 확보 필요 여부, 리소스 낭비 여부 모니터링.

## 13.2 LLMOps는 무엇이 다를까?
> 머신러닝, LLM 모델 차이점
- LLM은 기존 머신러닝 모델에 비해 훨씬 크고 일부 기업이 API 기반으로 상업용 모델 제공
- 머신러닝은 평가 지표가 명확한 작업에, LLM은 정량적 평가가 어려운, 생성 작업에 사용
### 13.2.1 상업용 모델과 오픈소스 모델 선택하기
> LLMOps는 MLOps보다 훨씬 크고 다양한 일을 할 수 있는 모델을 다룸
- 사용하려는 목적과 문제의 난이도에 따라 상업용 모델/ 오픈소스 모델 중 적절한 모델 선택

### 13.2.2 모델 최적화 방법의 변화
> 기본적으로 LLM은 사전 학습된 모델을 가져와 미세 조정 수행.
- 미세 조정 과정에서 모델 학습 최적화
> 프롬프트 구조화 작업
- 프롬프트를 기록해두고, 성능 평가 진행

## 13.3 LLM 평가하기

### 13.3.1 정량적 지표
> 텍스트 생성 작업 평가 시 사용하는 세 가지 정량 지표
- BLEU: 기계 번역 결과와 사람이 번역한 결과의 유사도를 측정해 번역 성능 평가
- ROUGE: 모델이 생성한 요약문과 사람이 작성한 참조 요약문 사이의 n-gram 중복도 측정
- PPL: 단어 생성 시 불확실성을 수치화
### 13.3.2 벤치마크 데이터셋을 활용한 평가
> 벤치마크 데이터셋: 다양한 모델의 성능을 비교하기 위해 공통으로 사용하는 데이터셋

### 13.3.3 사람이 직접 평가하는 방식
> 정성 평가 가능하나 시간 오래 걸리고 비용 많이 듦.

### 13.3.4 LLM을 통한 평가
> 80개의 선별한 멀티 턴 질문 데이터인 MT-Bench와 챗봇 아레나 데이터 활용하여 선호도 평가
### 13.3.5 RAG 평가
> 평가 기준
- 신뢰성: 생성된 응답이 검색된 맥락 데이터에 얼마나 사실적으로 부합하는지
- 답변 관련성: 생성된 답변이 요청과 얼마나 관련성이 있는지
- 맥락 관련성: 검색 결과인 맥락 데이터가 요청과 얼마나 관련 있는지