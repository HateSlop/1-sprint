# 12. 벡터 데이터베이스로 확장하기: RAG 구현하기
## 12.1 벡터 데이터베이스란
### 12.1.1 딥러닝과 벡터 데이터베이스
> 표현 학습: 데이터가 충분하면 모델이 알아서 특징 추출

> 벡터 데이터베이스 활용 방법
- 저장: 저장할 데이터를 벡터로 변환 후 벡터 DB에 저장
- 검색: 검섹할 데이터를 벡터로 변환하고 벡터 DB에서 검색
- 결과 반환: 벡터 DB에서 검색 쿼리의 임베딩과 거리가 가까운 벡터 찾아 반환
    - 유사도 계산: 유클리드 거리, 코사인 유사도, 내적

### 12.1.2 벡터 데이터베이스 지형 파악하기
> 벡터 데이터베이스 소프트웨어 종류
- 벡터 라이브러리
- 벡터 전용 데이터베이스
- 벡터 기능 추가 데이터베이스
> 벡터 데이터베이스 기능
- 메타 데이터의 저장 및 필터링
- 데이터의 백업 및 관리
- 모니터링, 관련 AI도구 등 에코시스템과의 통합
- 데이터 보안과 엑세스 관리

## 12.2 벡터 데이터베이스 작동 원리
### 12.2.1 KNN 검색과 그 한계
> 검색하려는 벡터와 가장 가까운 K개의 이웃 벡터 찾는 방식
- 직관적, 모든 데이터 조사하여 정확
- 데이터 많으면 연산량 증가, 확장성 떨어짐.
> 과정
- 인덱스 만들기
- 검색 하기(검색 시간과 재현율이 중요)

### 12.2.2 ANN 검색이란
> 대용량 데이터셋에서 주어진 쿼리 항목과 가장 유사한 항목을 효율적으로 찾는 방법
- 임베딩 벡터 빠르게 탐색할 수 있는 구조로, 검색 시 탐색 범위 좁히는 데 집중.
- IVF, HNSW
### 12.2.3 탐색 가능한 작은 세계(NSW)
> 완전히 랜덤한 그래프와 완전히 규칙적인 그래프 사이에 적당히 랜덤하게 연결된 그래프 상태
- 완전히 규칙적인 그래프보다 탐색 단계를 줄여줌.
- 지역 최솟값에서 탐색을 종료할 문제가 생김
### 12.2.4 계층 구조
> 연결 리스트
- 새로운 데이터 추가 및 삭제가 자유로움
- 탐색 속도 느림
> 탐색 속도 높이기 위해
- 데이터 정렬
    - 스킵 리스트
        - for n to 1;
            level(n) is included in level(n-1)
        - for n to 0:
            search(level(n));
## 12.3 실습: HNSW 인덱스의 핵심 파라미터 이해하기

### 12.3.1 파라미터 m 이해하기
> m: 추가하는 임베딩 벡터에 연결하는 간선의 수
- m값이 커지면 검색 품질 개선, m값이 감소하면 검색 시간 증가
### 12.3.2 파라미터 ef_construction 이해하기
> M개의 가장 가까운 벡터를 선택할 후보군
- M증가: 성능 증가, 색인 시간 증가. 메모리 사용량, 검색 시간은 영향 안받음.
### 12.3.3 파라미터 ef_search 이해하기

        
        